% \setchapterimage[6cm]{seaside}
\setchapterpreamble[u]{\margintoc}
\chapter{Meta-theory of \SetoidCC}
\labch{metatheory}

In this chapter, we develop the meta-theory of \SetoidCC to prove
the theorems that are presented in \cref{sec:properties}.

Firstly, in \cref{sec:logic-relat-with} we build a normalization model for \SetoidCC
in \Agda, based on the model for \MLTT presented by Abel 
\etal~\cite{Abel:POPL2018}. 
% 
By interpreting types as logical predicates on terms, we prove that 
every well-typed term of \SetoidCC has a normal form that can be computed
by reduction.

Then in \cref{sec:normalization-consequences}, we study the consequences of 
the normalization model. We explain how to deduce canonicity of \SetoidCC from
a proof of consistency, we show that conversion is decidable, and we give the 
outline of an algorithm for type-checking. 
% 
Except for the decidability of typing, all the proofs of this chapter have been
formally verified in \Agda. 

In \cref{sec:analys-norm-proof}, we explain how to replay the construction of
the normalization model in Martin-LÃ¶f Type Theory with W-types, a theory that is
weaker than the theory of \Agda. 
% 
From there, we deduce that \SetoidCC cannot express more integer functions than \MLTT. 
% 
This section is also supported by an \Agda development.

Finally, in \cref{sec:cons-seto-model} we construct a model of \SetoidCC in ZF 
set theory with Grothendieck universes, from which we obtain a proof of 
consistency (and therefore canonicity) for \SetoidCC. Furthermore, we make sure
that our model provides reasonable set-theoretic semantics for our system, so
that statements of \SetoidCC may be interpreted as natural statements of ZF set 
theory.

\section{The Normalization Model}
\label{sec:logic-relat-with}

\subsection{Overview of the Proof}

Since the construction of the normalization model is rather intricate, it might
be easy to get lost in the technical details and to miss the big idea. 
% 
Therefore, in hope that the reader will find it helpful, we start by giving a lengthy 
bird's eye view of the proof with references and comparisons to the existing
literature before diving head first into the actual proof in 
\cref{sec:reducbility-proof-rel}.

\paragraph*{Proving Normalization}

In dependent type theory, proving that every well-typed term is normalizing 
is a complex matter.
% 
If we try to prove it by naive induction on the typing derivations, we quickly 
get stuck on the case of the application rule, because we cannot obtain that 
\( t~u \) is normalizing from the hypotheses that $t$ and $u$ are normalizing.
%
Still, reasoning by induction on the typing derivations is pretty much our only 
option, as type theories are fundamentally inductive objects, presented by 
the inference rules.
% 
Thus what we really need is a better induction hypothesis, one that implies
normalization of well-typed terms but is also preserved by all the inference 
rules of the type theory.

When we are dealing with a type theory that is as sophisticated as \MLTT or \SetoidCC, 
the typical induction hypotheses get very complex, with cases specifically 
tailored to handle each basic type and a lot of interdependence.
% 
At this point, it becomes easier to present the proof as the construction of
a \emph{model} for the type theory: we interpret every type \( A \) as a pair 
of a predicate \( [A] \) that expresses the induction hypothesis for terms of 
type \( A \), and a binary relation \( [A]_= \) that gives the induction 
hypothesis for convertible elements of \( A \).
% 
\sideremark{The two predicates \( [A] \) and \( [A]_= \) could equivalently be 
  presented as a partial equivalence relations on terms, which is the more 
  traditional way to phrase it.}
% 
Next, we show by induction that all typing derivations are valid in the model,
meaning that if \( t : A \) is derivable then \( t \in [A] \) and that if
\( t \equiv u : A \) is derivable then \( [A]_=\ t\ u \).
% 
If we designed our predicates so that they imply normalization, we have our 
proof.
% 
Such models are traditionally built using the \emph{reducibility} technique
pioneered by Tait~\sidecite{Tait67}, or its reinterpretation in categorical language
that goes by the name \emph{gluing}~\sidecite{shulman_2015}.

In \sidecite{Abel:POPL2018}, Abel \etal present a normalization model for a 
subset of \MLTT that includes one predicative universe, dependent products and 
natural numbers with large elimination.
% 
They build their model in intensional type theory with induction-recursion, 
a meta-theory which is remarkably close to the theory being studied.
% 
Furthermore, they entirely formalized their proofs in \Agda, down to the proof
of decidability of conversion.
% 
In this chapter, we will extend their model to show normalization and decidability
of conversion for the full system \SetoidCC.
% 
We formalized our proofs in \Agda for a significant subset of \SetoidCC that
includes two predicative universes, the impredicative universe of propositions, 
dependent products, natural numbers and the observational equality. 
% 
Links to our code will be scattered thoughout the chapter, but 
the main file can be consulted at \refAgdaRoot{Everything}.

\paragraph*{Informal summary of the model of Abel \etal}
% 
Abel \etal start by defining the \emph{reducibility predicates}. 
Reducibility predicates are three proof-relevant predicates on untyped 
terms that are associated to some types of the theory:
% 
\begin{itemize}
\item the unary predicate \( {\tytmReco{\ell}{\Gamma}{\_}{A}{\Univ}} \) 
  defines the set of \emph{reducible terms} of type \( A \) in context \( \Gamma \),
\item the binary relation \( {\eqtmReco{\ell}{\Gamma}{\_}{\_}{A}{\Univ}} \), 
  defines \emph{reducible equality} between two reducible terms of type \( A \) in context \( \Gamma \),
\item and the unary predicate \( {\eqtyReco{\ell}{\Gamma}{A}{\_}{\Univ}} \) 
  defines the set of types \emph{reducibly equal} to \( A \) in context \( \Gamma \).
\end{itemize}
% 
Whenever a type \( A \) is equipped with these three reducibility predicates in a
context \( \Gamma \), we write \( \tytyReco{\ell}{\Gamma}{A}{\Univ} \) and we call 
\( A \) a \emph{reducible type}.

A typical reducibility predicate characterizes the behaviour that ``well-behaved''
terms of type \( A \) should exhibit: for instance, a term \( t \) is deemed
to be a reducible inhabitant of type \( B \to C \) if it reduces to a term 
\( {t'} \) in weak-head normal form, such that \( {t'} \) applied to
any reducible term of type \( B \) produces a reducible term of type \( C \)
(up to some technical details).

The reducibility predicates are also indexed by a level \( \ell \), which reflects 
the predicative nature of the universe hierarchy of \MLTT: reducibility is 
first defined at level $0$ to characterize types and terms that inhabit the 
smallest universe \( \Type_0 \).
% 
Then Abel \etal use reducibility at level 0 to define reducibility at level 1, 
that applies to types and terms that live in \( \Type_1 \)---in the case of
the type \( \Type_0 : \Type_1 \), they define
\[
\begin{array}{rcl}
  \tytmReco{1}{\Gamma}{A}{\Type_0}{\Type_1} & := & \tytyReco{0}{\Gamma}{A}{\Type_0} \\
  \eqtmReco{1}{\Gamma}{A}{B}{\Type_0}{\Type_1} & := & \eqtyReco{0}{\Gamma}{A}{B}{\Type_0}. 
\end{array}
\]
% 
And this definition is iterated to handle any universe level.

However, reducibility is not quite strong enough to build a model of \MLTT, 
so Abel \etal go on to define \emph{validity} which is the closure 
of reducibility under substitution.
% 
Only after this step can they prove the \emph{fundamental lemma} which shows 
that the validity model supports all the inference rules of their fragment of
\MLTT, and thus that every well-typed term can be interpreted in the validity
model. Since validity implies normalization, this concludes the proof.

If we want to construct a similar model for \SetoidCC, we will need to add
support for impredicative proof-irrelevant propositions and the observational 
equality.

\paragraph*{Adding Proof-Irrelevant Types}
% 
Gilbert \etal~\sidecite{gilbert:hal-01859964} extended the model of 
Abel \etal to add a universe of definitionally proof-irrelevant types.
Contrary to the universe \( \sProp \) of \SetoidCC, their universe is
predicative, and only contains \( \Pi \)-types and the false proposition.

In their proof, Gilbert \etal extend the reduction rules to the inhabitants of 
proof-irrelevant types, and they go on to prove normalization for both relevant
and irrelevant terms.
%
From normalization, they also deduce a proof of consistency for \MLTT 
extended with predicative proof-irrelevant types: any proof of the false 
proposition \( \Empty \) in an an empty context will reduce to a weak head 
normal form, and the only weak head normal forms that can inhabit 
\( \Empty \) are neutral terms. 
% 
But since there are no variables in the empty context, neutral terms cannot 
exist, so \( \Empty \) has no inhabitant in the empty context.

However, this strategy is not applicable in our setting. Contrary to the theory
studied by Gilbert \etal, \SetoidCC relies crucially on proof-irrelevant 
axioms such as \( \castreflName \), which do not have any clear reduction rule 
or normal forms.
%
Therefore we will drop the idea of having reduction rules for inhabitants of 
propositions, and we will only prove normalization for proof-relevant terms.
%
We argue that this is more faithful to the philosophy of computational
irrelevance, and results in a proof that is completely agnostic about
the proof-irrelevant content of the theory---we could postulate any
consistent proof-irrelevant axiom (even excluded middle!) and the normalization 
proof would carry through just as well.

Unfortunately, this means that consistency and canonicity do not follow
from normalization anymore. The reason is simple: since we gave up any
kind of control on the proof-irrelevant terms, we might have proofs
of \( \Empty \) in the empty context for all we can tell.
% 
But this also weakens our control on neutral terms in the proof-\emph{relevant} 
layer, as \( \Empty \)-elim can build an inhabitant of any proof-relevant type 
from a proof of \( \Empty \).
% 
Therefore, if we want to show canonicity, we need to show that there is no proof 
of \( \Empty \) in the empty context---in other words, that the theory is 
consistent.
% 
This idea of deriving canonicity from consistency already appeared in the work 
of Altenkirch \etal \sidecite{altenkirchAl:plpv2007}.

We will get around this issue by constructing two models: the normalization model
that provides us with normalization proofs, and a set-theoretic model from 
which we will derive a consistency proof for \SetoidCC. This second model is 
presented in \cref{sec:cons-seto-model}.

\paragraph*{Adding Support for Impredicativity} 
% 
Impredicativity is famously difficult to model in reducibility proofs, because
it breaks the well-foundedness of the type hierarchy: impredicative dependent
products may have an arbitrarily large domain, while still being at the 
bottom of the universe hierarchy.
% 
The standard way to build a normalization model for impredicative theories that 
avoids self-referential issues is to use \emph{reducibility candidates}, the 
device introduced by Girard~\sidecite{girard72} to prove normalization for System F.
% 
Fortunately, in \SetoidCC the impredicative dependent products are 
propositions, and thus proof-irrelevant. As we explained above, we do
not prove normalization for computationally irrelevant terms, so we will not 
need Girard's reducibility candidates.

However, we still need to define reducibility for \( \sProp \),
which is a proof-relevant type. And since its sort is \( \Type_0 \), the 
reducibility predicates for \( \sProp \) should be defined at level 0, without
any knowledge of the model for higher universes. 
% 
So, when should an impredicative dependent product be reducible?
% 
In the model of Abel \etal, dependent products are deemed reducible when
their domain is reducible, and their codomain is reducible 
for any reducible element of the domain. 
% 
But an impredicative dependent product may have an arbitrarily large domain,
so this definition will not work.
% 
We will break out of the circularity by defining a weaker notion of reducibility 
for impredicative types that does not provide any control on the domain and 
codomain of dependent products.

Interestingly, this weakened reducibility means that we will not be able to prove 
the fundamental lemma directly on the economic rules we presented 
in \cref{ch:observational}, which omit plenty of well-formedness hypotheses for 
the sake of readability 
% 
(for instance, the rule~\nameref{inferrule:pi-intro} does not ask for 
well-formedness of the involved types).
% 
In their work, Abel \etal were able to define the model directly on the economic 
rules by collecting the well-formedness hypotheses in the reducibility predicates---but 
we are not, so we will construct our model using more verbose inference rules.
% 
Once the fundamental lemma is proved, we will be able to show that the economic 
rules of \cref{ch:observational} do in fact contain sufficient information to 
recover these additional hypotheses (see \cref{sec:normalization-consequences}).

This concludes our bird's eye view of the proof. It only remains to roll up our 
sleeves and unfold our strategy.
% 
\sideremark{We will present a somewhat informal version of the proof where some technical 
details are left implicit, and encourage the reader who is interested in
complete formal proofs to have a look at the \Agda development.}

\subsection{Defining Reducibility}
\label{sec:reducbility-proof-rel}

Following Abel \etal \cite{Abel:POPL2018}, our constructions starts with the 
definition of the four reducibility predicates, which are also annotated with
a sort in our version---see \cref{fig:log-rel-judgments}.

\begin{figure*}[!h]
  \[
\begin{array}{lr}
  \tytyR{\ell}{\Gamma}{A}{\Univ} & \text{A is a reducible type of sort \( \Univ \) at level \( \ell \) in context \( \Gamma \)} \\
  \eqtyR{\ell}{\Gamma}{A}{B}{\Univ} & \text{A and B are reducibly equal types of sort \( \Univ \) at level \( \ell \) in context \( \Gamma \)} \\
  \tytmR{\ell}{\Gamma}{t}{A}{\Univ} & \text{t is a reducible term at level \( \ell \) of type \( A \) in context \( \Gamma \)} \\
  \eqtmR{\ell}{\Gamma}{t}{u}{A}{\Univ} & \qquad\text{t and u are reducibly equal terms at level \( \ell \) of type \( A \) in context \( \Gamma \)}
\end{array}
\]
\caption{The four reducibility predicates}
\label{fig:log-rel-judgments}
\end{figure*}

These reducibility predicates are defined by induction-recursion, as 
illustrated in \cref{fig:logrel-ind-rec}.
%
The reducible types are defined inductively with eleven constructors, one 
corresponding to each basic type former of \SetoidCC and one for neutral types. 
% 
Each constructor takes as argument a proof of an auxiliary predicate of the 
form \( \Gamma \Vdash_X t \) that packs information specific to the 
type \( X \), that we will define below.
%
% \sideremark{This technically means that the reducibility predicates for
% terms and equalities should have an extra argument of type 
% \( \tytyR{\ell}{\Gamma}{A}{\Univ} \). However, we leave this argument 
% implicit
% (cf \refAgda{}{Irrelevance}), .}
% 
The logical relations on terms and equalities are simultaneously
defined by recursion on proofs of \( \tytyR{\ell}{\Gamma}{A}{\Univ} \), using
more auxiliary predicates.

Remark that some types that we defined in \cref{ch:observational} do not appear 
in the definition of reducibility.
% 
First, we do not need to account for \( \Unit \), existential types 
or propositional truncation, because they are defined in terms of \( \Empty \)
and dependent products.
%
What's more, the observational equality does not appear in the definition
either.
This is because it does not play the role of a type constructor, but
rather that of a destructor that computes by pattern-matching on types.
Therefore, all types with the shape \( \Obseq[A]{t}{u} \) will reduce to
simpler types, unless they are neutral, in which case they are handled
by the generic rule for neutral terms.

\begin{figure*}
  \begin{small}
\begin{flalign*}
  \begin{array}{lcl}
\_ \Vdash_\ell \_ : \_ & : & (\Gamma : \Context) \to (t : \Term) \to (\Univ : \Sort) \to \AgdaSet{} \\
\_ \Vdash_\ell \_ : \_ & \bnfis & \Vne : \forall\ \Gamma\ t\ \Univ \to
                          (\Gamma \Vdash_{\mathsf{ne}} t : \Univ) \to
                          \Gamma \Vdash_\ell t : \Univ\\
               & \sep & \Vforall : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\Pi \mathsf{i}} t) \to
                          \Gamma \Vdash_\ell t : \sProp\\
               & \sep & \Vempty : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\bot} t) \to
                          \Gamma \Vdash_\ell t : \sProp\\
               & \sep & \VU : \forall\ \Gamma\ t\ i \to
                          (\Gamma \Vdash_{\mathsf{U}} t : \Type_i) \to
                          \Gamma \Vdash_\ell t : \Type_i\\
               & \sep & \VOmega : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\Omega} t) \to
                          \Gamma \Vdash_\ell t : \Type_0\\
               & \sep & \Vnat : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\Nat} t) \to
                          \Gamma \Vdash_\ell t : \Type_0\\
               & \sep & \Vpi : \forall\ \Gamma\ t\ i \to
                          (\Gamma \Vdash_{\Pi} t : \Type_i) \to
                          \Gamma \Vdash_\ell t : \Type_i\\
               & \sep & \Vsigma : \forall\ \Gamma\ t\ i \to
                          (\Gamma \Vdash_{\Sigma} t : \Type_i) \to
                          \Gamma \Vdash_\ell t : \Type_i\\
               & \sep & \Vbox : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\Box} t) \to
                          \Gamma \Vdash_\ell t : \Type_0\\
               & \sep & \Vquo : \forall\ \Gamma\ t\ i \to
                          (\Gamma \Vdash_{\mathsf{Q}} t : \Type_i) \to
                          \Gamma \Vdash_\ell t : \Type_i\\
               & \sep & \Vid : \forall\ \Gamma\ t\ i \to
                          (\Gamma \Vdash_{\mathsf{Id}} t : \Type_i) \to
                          \Gamma \Vdash_\ell t : \Type_i\\
               %% & \sep & \Vemb : \forall\ \ell'\ \Gamma\ t\ s \to
               %%            \ell' < \ell \to
               %%            \Gamma \Vdash_{\ell'} t : s \to
               %%            \Gamma \Vdash_{\ell} t : s\\
  \end{array} &&
\end{flalign*}

\begin{flalign*}
  \begin{array}{lcl}
\_ \Vdash_\ell \_ \equiv \_ : \_ & : & (\Gamma : \Context) \to (A : \Term) \to (B : \Term) \to (s : \Sort) \to \{ \Gamma \Vdash_\ell A : s \} \to \AgdaSet{} \\
\Gamma \Vdash_\ell A \equiv B : s\ \{ \VX \} & = & \Gamma \Vdash_{X} A \equiv B : s
  \qquad \text{for all }\ X \in \{\mathsf{ne}, {\Pi \mathsf{i}}, \bot, \mathsf{U}, \Omega, \mathbb{N}, \Pi, \Sigma, \Box, \mathsf{Q}, \mathsf{Id} \}
  \end{array} &&
\end{flalign*}

\begin{flalign*}
  \begin{array}{lcl}
\_ \Vdash_\ell \_ : \_ : \_ & : & (\Gamma : \Context) \to (t : \Term) \to (A : \Term) \to (s : \Sort) \to \{ \Gamma \Vdash_\ell A : s \} \to \AgdaSet{} \\
\Gamma \Vdash_\ell t : A : s\ \{ \VX \} & = & \Gamma \Vdash_{X} t : A: s
  \qquad \text{for all }\ X \in \{\mathsf{ne}, {\Pi \mathsf{i}}, \bot, \mathsf{U}, \Omega, \mathbb{N}, \Pi, \Sigma, \Box, \mathsf{Q}, \mathsf{Id} \}
  \end{array} &&
\end{flalign*}

\begin{flalign*}
  \begin{array}{lcl}
\_ \Vdash_\ell \_ \equiv \_ : \_ : \_ & : & (\Gamma : \Context) \to (t\ u : \Term) \to (A : \Term) \to (s : \Sort) \to \{ \Gamma \Vdash_\ell A : s \} \to \AgdaSet{} \\
\Gamma \Vdash_\ell t \equiv u : A : s\ \{ \VX \} & = & \Gamma \Vdash_{X} t \equiv u : A: s
  \qquad \text{for all }\ X \in \{\mathsf{ne}, {\Pi \mathsf{i}}, \bot, \mathsf{U}, \Omega, \mathbb{N}, \Pi, \Sigma, \Box, \mathsf{Q}, \mathsf{Id} \}
  \end{array} &&
\end{flalign*}
\end{small}
  \caption{Inductive-recursive presentation of reducibility}
  \label{fig:logrel-ind-rec}
\end{figure*}

%% As is customary in reducibility proofs~\sidecite{girard72}, these
%% judgments imply normalization, are closed under weak head expansion,
%% and are verified by all neutral terms.

\subsection{Reducibility for the Proof-Relevant Layer}

We now give the definition of all these auxiliary predicates, starting
with the predicates for neutral types.

\paragraph{Proof-relevant Neutral Types}

% The first kind of reducible type are neutral type.
\[
  \inferrule{\redT{\Gamma}{A}{N}{\Type_i} \\ \neutral{N}}
  {\tytyR{\mathsf{ne}}{\Gamma}{A}{\Type_i}}
\]
% 
\sideremark{Our reduction strategy is the weak-head reduction that we defined
in \cref{sec:weak-head}.}
% 
Terms which reduce to neutral types are reducible types.
In this rule, the premise \( \redT{\Gamma}{A}{N}{\Type_i} \) means that \( A \) 
reduces to a term \( N \) in a finite number of steps (possibly zero), and that 
both \( A \) and \( N \) are of sort \( \Type_i \) in context \( \Gamma \).
%
When $A$ is reducible to a neutral type, we also define:
% Given a derivation
% \( \metatm{\mathscr{A}}{\tytyR{\ell}{\Gamma}{A}} \) built by this rule, we define:
\begin{itemize}
  \item \( \eqtyR{\mathsf{ne}}{\Gamma}{A}{B}{\Type_i} \) if there is a neutral term \( M \) such that
    \( \redT{\Gamma}{B}{M}{\Type_i} \) and \( \eqtm{\Gamma}{N}{M}{\Type_i} \).
  \item \( \tytmR{\mathsf{ne}}{\Gamma}{t}{A}{\Type_i} \) if there is a neutral term \( n \) such that
    \( \redT{\Gamma}{t}{n}{N} \).
  \item \( \eqtmR{\mathsf{ne}}{\Gamma}{t}{u}{A}{\Type_i} \) if there are neutral terms \( n, m \) such that
    \( \redT{\Gamma}{t}{n}{N} \) and \( \redT{\Gamma}{u}{m}{N} \), and
    \( \eqtm{\Gamma}{n}{m}{N} \).
\end{itemize}

In other words, being a reducible inhabitant of a neutral type is simply
reducing to a neutral term.

\paragraph{Natural Numbers}
\[
  \inferrule{\redT{\Gamma}{A}{\Nat}{\Type_0}}
            {\Gamma \Vdash_{\mathbb{N}} A}
\]
Terms which reduce to $\Nat$ are reducible types. In case \( A \) is reducible 
to \( \Nat \), we also define:
 % Given a derivation \( \metatm{\mathscr{A}}{\tytyR{\ell}{\Gamma}{A}} \) built by this rule, we
% define:
\begin{itemize}
  \item \( \Gamma \Vdash_{\mathbb{N}} A \equiv B \) if \( \redT{\Gamma}{B}{\Nat}{\Type_0} \).
  \item \( \Gamma \Vdash_{\mathbb{N}} t : A \) if there is a normal form \( t' \) such that
    \( \redT{\Gamma}{t}{t'}{\Nat} \) and \( \Gamma \Vdash_{\mathbb{N}\mathsf{t}} t' \), which is inductively
    defined by
    \[
      \inferrule{ }
                {\nattmR{\Gamma}{\zero}}
      \quad
      \inferrule{\nattmR{\Gamma}{t}}
                {\nattmR{\Gamma}{\suc{t}}}
      \quad
      \inferrule{\tytm{\Gamma}{n}{\Nat}
                \\ \text{\( n \) is neutral}}
                {\nattmR{\Gamma}{n}}
    \]
  \item \( \Gamma \Vdash_{\mathbb{N}} t \equiv u : A \) if there are normal forms \( t', u' \) such that
    \( \redT{\Gamma}{t}{t'}{\Nat} \) and
    \( \redT{\Gamma}{u}{u'}{\Nat} \), and
    \( \nateqR{\Gamma}{t'}{u'} \), which is inductively defined by
\begin{mathpar}
      \inferrule{ }
                {\nateqR{\Gamma}{\zero}{\zero}}
      \and
      \inferrule{\nateqR{\Gamma}{t}{u}}
                {\nateqR{\Gamma}{\suc{t}}{\suc{u}}}
      \and
      \inferrule{\eqtm{\Gamma}{n}{m}{\Nat}
                \\ \text{\( n, m \) are neutral}}
                {\nateqR{\Gamma}{n}{m}}
\end{mathpar}
\end{itemize}

These definitions mean that a term is a reducible natural number when it 
reduces to either zero, a neutral term or a successor of a reducible 
natural number.

\paragraph{Predicative Universes}
\[
  \inferrule{\redT{\Gamma}{A}{\Type_i{}}{\Type_{i+1}}}
            {\tytyR{\mathsf{U}}{\Gamma}{A}{\Type_{i+1}}}
            { \substack{i < \ell}}
\]
Terms which reduce to a predicative universe are reducible types. In case \( A \) 
is reducible to a predicative universe, we also define:
\begin{itemize}
  \item \( \eqtyR{\mathsf{U}}{\Gamma}{A}{B}{\Type_{i+1}} \) if \( \redT{\Gamma}{B}{\Type_i{}}{\Type_{i+1}} \).
  \item \( \tytmR{\mathsf{U}}{\Gamma}{t}{A}{\Type_{i+1}} \) if there is a normal form \( t' \) such that
    \( \redT{\Gamma}{t}{t'}{\Type_i{}} \), and \( \tytyR{i}{\Gamma}{t}{\Type_i} \)

    (which is already defined by induction hypothesis, since
    \( i < \ell \)).
  \item \( \eqtmR{\mathsf{U}}{\Gamma}{t}{u}{A}{\Type_{i+1}} \) if there are normal forms \( t', u' \) such that
    \( \redT{\Gamma}{t}{t'}{\Type_i{}} \)
    and \( \redT{\Gamma}{u}{u'}{\Type_i{}} \), and
    \( \tytyR{i}{\Gamma}{t}{\Type_i} \), \( \tytyR{i}{\Gamma}{u}{\Type_i} \), and \( \eqtyR{i}{\Gamma}{t}{u}{\Type_i} \).
\end{itemize}

According to these definitions, being a reducible inhabitant of a predicative
universe is the same as being a proof-relevant reducible type: either a 
neutral, or a dependent product, etc.
% 
This is the only case that recursively calls the definition of reducibility
at a lower level, forcing us to define the whole affair by induction on 
\( \ell \).

\paragraph{Proof-relevant Dependent Products}

  \begin{mathpar}
  \inferrule{\redT{\Gamma}{A}{\Depfunannotated{F}{G}{}{\Univ}{\Type_i}}{\Type_{\mathrm{max}(\Univ, i)}}
            \\ \tytm{\Gamma}{F}{\Univ}
            \\ \tytm{\extctx{\Gamma}{F}}{G}{\Type_i}
            \\ \forall \wkrho,\ \tytyR{\ell}{\Delta}{F[\rho]}{\Univ}
            \\ \forall \wkrho,\ \metaimply{\tytmR{\ell}{\Delta}{a}{F[\rho]}{\Univ}}{\tytyR{\ell}{\Delta}{G[\rho, a]}{\Type_i}}
            \\ \forall \wkrho,
              {\tytmR{\ell}{\Delta}{a}{F[\rho]}{\Univ}}
              \to {\tytmR{\ell}{\Delta}{b}{F[\rho]}{\Univ}}
              \to {\eqtmR{\ell}{\Delta}{a}{b}{F[\rho]}{\Univ}}
              \to {\eqtyR{\ell}{\Delta}{G[\rho, a]}{G[\rho, b]}{\Type_i}}}
            {\tytyR{\Pi}{\Gamma}{A}{\Type_{\mathrm{max}(\Univ, i)}}}
  \end{mathpar}
%
This rule describes the condition for $A$ to be reducible to a proof-relevant
dependent product.
%
We introduced quite a bit of notation here, so we go over the premises one by 
one.
% 
The first three premises state that \( A \) reduces to a dependent product in a
finite number of steps, and that the domain and codomain of the dependent 
product are well-formed types.
% 
\sideremark{Despite the similarity with an inclusion symbol, the notation 
\( \Delta â \Gamma \) means that all types of \( \Gamma \) appear in 
\( \Delta \).}
% 
The fourth premise asks for the domain \( F \) to be a reducible type under any
weakening: the notation \( \wkrho \) means that \( \rho \) is a weakening from
a context \( \Delta \) to the context \( \Gamma \), and the notation 
\( F[\rho] \) represents the result of weakening the free variables of \( F \).
% 
The fifth premise says that given any weakening \( \rho \) and a term \( a \)
which is a reducible inhabitant of \( F[\rho] \), the term we obtain by
applying the weakening \( \rho \) to all free variables of \( G \) except for
\( x \), and then substituting \( a \) for \( x \) is reducible.
This term is noted \( G[\rho, a] \). 
% 
Finally, the last premise states that under any weakening, applying \( G \) to
reducibly equal inhabitants of \( F \) results in two reducibly equal types.

\sideremark[*1]{Thus, reducibility has the structure of a \emph{presheaf} over the
category of weakenings. These generalized hypotheses are really an embodiment of
the presheaf exponential.}
The reader might be wondering why we generalize the last three premises 
under any weakening. The simple explanation is that we want reducibility to be
stable under weakening, and we will not be able to prove it by induction on the
definition because of the negative occurences---so we generalize any premise
that mentions reducibility on the left of an arrow.

When $A$ is reducible to a dependent product, we define:
\begin{itemize}
  \item \( \eqtyR{\Pi}{\Gamma}{A}{B}{\Type_{\mathrm{max}(\Univ, i)}} \) if there are terms \( F' \) and \( G' \) such that
    \begin{itemize}
      \item \( \redT{\Gamma}{B}{\Depfun{F'}{G'}}{\Type_{\mathrm{max}(\Univ, i)}} \) 
      \item \( \eqtm{\Gamma}{\Depfun{F}{G}}{\Depfun{F'}{G'}}{\Type_{\mathrm{max}(\Univ, i)}} \)
      \item \( \forall \wkrho.\ \ \eqtyR{\ell}{\Delta}{F[\rho]}{F'[\rho]}{\Univ} \)
      \item \( \forall \wkrho.\ \ {\tytmR{\ell}{\Delta}{a}{F[\rho]}{\Univ}} \) 
            \\ \( \phantom{\forall \wkrho} \to {\eqtyR{\ell}{\Delta}{G[\rho, a]}{G'[\rho, a]}{\Type_i}} \).
      \end{itemize}
    \item \( \tytmR{\Pi}{\Gamma}{t}{A}{{\Type_{\mathrm{max}(\Univ, i)}}} \) if there is a normal form \( t' \) such that
    \begin{itemize}
      \item \( \redT{\Gamma}{t}{t'}{\Depfun{F}{G}} \)
      \item \( \forall \wkrho.\ \ {\tytmR{\ell}{\Delta}{a}{F[\rho]}{\Univ}} \) 
            \\ \( \phantom{\forall \wkrho} \to {\tytmR{\ell}{\Delta}{t'[\rho]\ a}{G[\rho, a]}{\Type_i}} \)
      \item \( \forall \wkrho.\ {\tytmR{\ell}{\Delta}{a}{F[\rho]}{\Univ}} \)
            \\ \( \phantom{\forall \wkrho} \to {\tytmR{\ell}{\Delta}{b}{F[\rho]}{\Univ}} \to {\eqtmR{\ell}{\Delta}{a}{b}{F[\rho]}{\Univ}} \)
            \\ \( \phantom{\forall \wkrho} \to {\eqtmR{\ell}{\Delta}{t'[\rho]\ a}{t'[\rho]\ b}{G[\rho,a]}{\Type_i}} \).
    \end{itemize}
  \item \( \eqtmR{\Pi}{\Gamma}{t}{u}{A}{\Type_{\mathrm{max}(\Univ, i)}} \) if there are normal forms \( t', u' \) such that
    \begin{itemize}
      \item \( \redT{\Gamma}{t}{t'}{\Depfun{F}{G}} \)
      and \( \redT{\Gamma}{u}{u'}{\Depfun{F}{G}} \)
      \item \( \eqtm{\Gamma}{t'}{u'}{\Depfun{F}{G}} \)
      % \item \( \tytmR{\Pi}{\Gamma}{t}{A}{\Type_{\mathrm{max}(\Univ, i)}} \) 
      %       and \( \tytmR{\Pi}{\Gamma}{u}{A}{\Type_{\mathrm{max}(\Univ, i)}} \)
      \item \( \forall \wkrho.\ \ {\tytmR{\ell}{\Delta}{a}{F[\rho]}{\Univ}} \)
            \\ \( \phantom{\forall \wkrho} \to {\eqtmR{\ell}{\Delta}{t'[\rho]\ a}{u'[\rho]\ a}{G[\rho, a]}{\Type_i}} \).
    \end{itemize}
  \end{itemize}

These definitions deem a term to be a reducible dependent function when it
reduces to either a neutral term or a lambda-abstraction, and it sends 
reducible inhabitant of the domain to reducible inhabitants of the codomain.
% 
Note that in the three definitions above, we talk about reducibility of 
inhabitants of the domain and the codomain. 
We know that these reducibility predicates are well-defined because we assumed
that the domain and the codomain are reducible types when we supposed
that \( A \) is reducible to a dependent product.

\paragraph{Dependent Sums}

\begin{mathpar}
\inferrule{\redT{\Gamma}{A}{\Depsumannotated{F}{G}{}{\Type_i}{\Type_j}}{\Type_{\mathrm{max}(i,j)}}
          \\ \tytm{\Gamma}{F}{\Type_i}
          \\ \tytm{\extctx{\Gamma}{F}}{G}{\Type_j}
          \\ \forall \wkrho,\ \tytyR{\ell}{\Delta}{F[\rho]}{\Type_i}
          \\ \forall \wkrho,\ \metaimply{\tytmR{\ell}{\Delta}{a}{F[\rho]}{\Type_i}}{\tytyR{\ell}{\Delta}{G[\rho, a]}{\Type_j}}
          \\ \forall \wkrho,
            {\tytmR{\ell}{\Delta}{a}{F[\rho]}{\Type_i}}
            \to {\tytmR{\ell}{\Delta}{b}{F[\rho]}{\Type_i}}
            \to {\eqtmR{\ell}{\Delta}{a}{b}{F[\rho]}{\Type_i}}
            \to {\eqtyR{\ell}{\Delta}{G[\rho, a]}{G[\rho, b]}{\Type_j}}}
          {\tytyR{\Sigma}{\Gamma}{A}{\Type_{\mathrm{max}(i,j)}}}
\end{mathpar}

When \( A \) reduces to a dependent sum \( \Depsum{F}{G} \) such that \( F \) 
and \( G \) verify the same conditions as for the dependent product, then 
\( A \) is a reducible type.
% 
In this case, we define:
\begin{itemize}
  \item \( \eqtyR{\Sigma}{\Gamma}{A}{B}{\Type_{\mathrm{max}(i,j)}} \) if there are terms \( F' \) and \( G' \) such that
    \begin{itemize}
      \item \( \redT{\Gamma}{B}{\Depsum{F'}{G'}}{\Type_{\mathrm{max}(i,j)}} \) 
      \item \( \eqtm{\Gamma}{\Depsum{F}{G}}{\Depsum{F'}{G'}}{\Type_{\mathrm{max}(i,j)}} \)
      \item \( \forall \wkrho.\ \ \eqtyR{\ell}{\Delta}{F[\rho]}{F'[\rho]}{\Type_i} \)
      \item \( \forall \wkrho.\ \ {\tytmR{\ell}{\Delta}{a}{F[\rho]}{\Type_i}} \) 
            \\ \( \phantom{\forall \wkrho} \to {\eqtyR{\ell}{\Delta}{G[\rho, a]}{G'[\rho, a]}{\Type_j}} \).
      \end{itemize}
    \item \( \tytmR{\Sigma}{\Gamma}{t}{A}{{\Type_{\mathrm{max}(i,j)}}} \) if there is a normal form \( t' \) such that
    \begin{itemize}
      \item \( \redT{\Gamma}{t}{t'}{\Depsum{F}{G}} \)
      \item \( \forall \wkrho.\ \ {\tytmR{\ell}{\Delta}{\relfst{t'[\rho]}}{F[\rho]}{\Type_i}} \) 
      \item \( \forall \wkrho.\ \ {\tytmR{\ell}{\Delta}{\relsnd{t'[\rho]}}{G[\rho, \relfst{t'[\rho]}]}{\Type_j}}. \)
    \end{itemize}
  \item \( \eqtmR{\Sigma}{\Gamma}{t}{u}{A}{\Type_{\mathrm{max}(i,j)}} \) if there are normal forms \( t', u' \) such that
    \begin{itemize}
      \item \( \redT{\Gamma}{t}{t'}{\Depsum{F}{G}} \)
      and \( \redT{\Gamma}{u}{u'}{\Depsum{F}{G}} \)
      \item \( \eqtm{\Gamma}{t'}{u'}{\Depsum{F}{G}} \)
      % \item \( \tytmR{\Sigma}{\Gamma}{t}{A}{\Type_{\mathrm{max}(i,j)}} \) 
      %       and \( \tytmR{\Sigma}{\Gamma}{u}{A}{\Type_{\mathrm{max}(i,j)}} \)
      \item \( \forall \wkrho.\ \ {\eqtmR{\ell}{\Delta}{\relfst{t'[\rho]}}{\relfst{u'[\rho]}}{F[\rho]}{\Type_i}} \) 
      \item \( \forall \wkrho. \) \\ \({}\quad {\eqtmR{\ell}{\Delta}{\relsnd{t'[\rho]}}{\relsnd{u'[\rho]}}{G[\rho, \relfst{t'[\rho]}]}{\Type_j}}. \)
    \end{itemize}
\end{itemize}
Thus, a term is a reducible inhabitant of \( A \) when it reduces to either a 
neutral term or a dependent pair, and both of its projections are reducible.

\paragraph*{Box types}
\[
  \inferrule{\redT{\Gamma}{A}{\Boxt{A'}}{\Type_0}
            \\ \tytm{\Gamma}{A'}{\sProp}
            \\ \tytyR{\ell}{\Gamma}{A'}{\sProp}}
            {\Gamma \Vdash_{\Box} A}
\]
If \( A \) reduces to a boxed reducible proposition, then \( A \) is a 
reducible type. In which case, we define:
\begin{itemize}
  \item \( \eqtyR{\Box}{\Gamma}{A}{B}{\Type_0} \) if there is a term \( B' \) such that
    \begin{itemize}
      \item \( \redT{\Gamma}{B}{\Boxt{B'}}{\Type_0} \)
      \item \( \eqtyR{\ell}{\Gamma}{A'}{B'}{\sProp} \)
    \end{itemize}
  \item \( \tytmR{\Box}{\Gamma}{t}{A}{\Type_0} \) if there is a normal form \( t' \) such that
    \( \redT{\Gamma}{t}{t'}{\Boxt{A'}} \) and \( \boxtmR{\Gamma}{t'} \), which is defined by
    \begin{mathpar}
      \inferrule{\tytm{\Gamma}{t}{A'}}
                {\boxtmR{\Gamma}{\boxt{t}}}
      \and
      \inferrule{\tytm{\Gamma}{n}{\Boxt{A'}}
                \\ \text{\( n \) is neutral}}
                {\boxtmR{\Gamma}{n}}
    \end{mathpar}
  \item \( \eqtmR{\Box}{\Gamma}{t}{u}{A}{\Type_i} \) if there are normal forms \( t', u' \) such that
    \( {\redT{\Gamma}{t}{t'}{\Boxt{A'}}} \), \( {\redT{\Gamma}{u}{u'}{\Boxt{A'}}} \), and
    \( {\boxeqR{\Gamma}{t'}{u'}} \), which is defined by
    \begin{mathpar}
      \inferrule{\tytm{\Gamma}{t}{A'} \\ \tytm{\Gamma}{u}{A'}}
                {\boxeqR{\Gamma}{\boxt{t}}{\boxt{u}}}
      \and
      \inferrule{\eqtm{\Gamma}{n}{m}{\Boxt{A'}}
                \\ \text{\( n, m \) are neutral}}
                {\boxeqR{\Gamma}{n}{m}}
    \end{mathpar}
\end{itemize}
In other words, an inhabitant of a box type is reducible when it reduces
to either a boxed proof, or a neutral term.

\paragraph*{Quotients}

\[
  \inferrule{\redT{\Gamma}{A}{\Quo{A'}{(R,R_r,R_s,R_t)}}{\Type_i}
            \\ \tytm{\Gamma}{A'}{\Type_i}
            \\ \forall \wkrho.\ \ \tytyR{\ell}{\Gamma}{A'[\rho]}{\Type_i}
            \\ \tytmR{\ell}{\Gamma}{R}{\Fun{A'}{\Fun{A'}{\sProp}}}{\Type_i}
            \\ \tytm{\Gamma}{R_r}{\Depfun{A'}{R\ x\ x}}
            \\ \tytm{\Gamma}{R_s}{\Depfun[x,y]{A'}{\Fun{R\ x\ y}{R\ y\ x}}}
            \\ \tytm{\Gamma}{R_t}{\Depfun[x,y,z]{A'}{\Fun{R\ x\ y}{\Fun{R\ y\ z}{R\ x\ z}}}}}
            {\tytyR{\mathsf{Q}}{\Gamma}{A}{\Type_i}}
\]
This rule stipulates that \( A \) is a reducible type if it reduces to a 
quotient type \( \Quo{A'}{R} \), its underlying type \( A' \) is reducible 
under any substitution, and \( R \) is a reducible relation on \( A' \). 
Note that to enunciate this last condition, we need to make sure that the
type of relations on \( A' \) is reducible, which is deduced from the
reducibility of \( A' \) and of \( \sProp \).

If \( A \) is reducible to a quotient type, we define:
\begin{itemize}
  \item \( \eqtyR{\mathsf{Q}}{\Gamma}{A}{B}{\Type_i} \) if there are terms \( B', Q, Q_r, Q_s, Q_t \) such that
    \begin{itemize}
      \item \( \redT{\Gamma}{B}{\Quo{B'}{(Q,Q_r,Q_s,Q_t)}}{\Type_i} \)
      \item \( \forall \wkrho.\ \ \eqtyR{\ell}{\Delta}{A'[\rho]}{B'[\rho]}{\Type_i} \)
      \item \( \eqtmR{\ell}{\Gamma}{R}{Q}{\Fun{A'}{\Fun{A'}{\sProp}}}{\Type_i} \).
      % \item \( \tytm{\Gamma}{Q_r}{\Depfun{B'}{Q\ x\ x}} \)
      % \item \( \tytm{\Gamma}{Q_s}{\Depfun[x,y]{B'}{\Fun{Q\ x\ y}{Q\ y\ x}}} \)
      % \item \( \tytm{\Gamma}{Q_t}{\Depfun[x,y,z]{B'}{\Fun{Q\ x\ y}{\Fun{Q\ y\ z}{Q\ x\ z}}}}} \)
    \end{itemize}
  \item \( \tytmR{\mathsf{Q}}{\Gamma}{t}{A}{\Type_i} \) if there is a normal form \( t' \) such that
    \( \redT{\Gamma}{t}{t'}{\Quo{A'}{R}} \) and \( \quotmR{\Gamma}{t'} \), which is defined by
    \begin{mathpar}
      \inferrule{\tytmR{\ell}{\Gamma}{t}{A'}{\Type_i}}
                {\quotmR{\Gamma}{\quo{t}}}
      \and
      \inferrule{\tytm{\Gamma}{n}{\Quo{A'}{R}}
                \\ \text{\( n \) is neutral}}
                {\quotmR{\Gamma}{n}}
    \end{mathpar}
  \item \( \eqtmR{\mathsf{Q}}{\Gamma}{t}{u}{A}{\Type_0} \) if there are normal forms \( t', u' \) such that
    \( {\redT{\Gamma}{t}{t'}{\Quo{A'}{R}}} \), \( {\redT{\Gamma}{u}{u'}{\Quo{A'}{R}}} \), and
    \( {\quoeqR{\Gamma}{t'}{u'}} \), which is defined by
    \begin{mathpar}
      \inferrule{\eqtmR{\ell}{\Gamma}{t}{u}{A'}{\Type_i}}
                {\quoeqR{\Gamma}{\quo{t}}{\quo{u}}}
      \and
      \inferrule{\eqtm{\Gamma}{n}{m}{\Quo{A'}{R}}
                \\ \text{\( n, m \) are neutral}}
                {\quoeqR{\Gamma}{n}{m}}
    \end{mathpar}
\end{itemize}
In other words, an inhabitant of a quotient type is reducible when it reduces
to either a projection of a reducible term, or a neutral term.

\paragraph*{Inductive Identity Types}

\[
  \inferrule{\redT{\Gamma}{A}{\Id{A'}{t}{u}}{\Type_i}
            \\ \tytyR{\ell}{\Gamma}{A'}{\Type_i}
            \\ \tytmR{\ell}{\Gamma}{t}{A'}{\Type_i}
            \\ \tytmR{\ell}{\Gamma}{u}{A'}{\Type_i}}
            {\tytyR{\mathsf{Id}}{\Gamma}{A}{\Type_i}}
\]
When $A$ reduces to an identity type between two reducible inhabitants of
a reducible type, then \( A \) is reducible. In this case, we define:
\begin{itemize}
  \item \( \eqtyR{\mathsf{Id}}{\Gamma}{A}{B}{\Type_i} \) if there are terms \( B', t', u' \) such that
    \begin{itemize}
      \item \( \redT{\Gamma}{B}{\Id{B'}{t'}{u'}}{\Type_i} \)
      \item \( \eqtyR{\ell}{\Gamma}{A'}{B'}{\Type_i} \)
      \item \( \eqtmR{\ell}{\Gamma}{t}{t'}{A'}{\Type_i} \)
      \item \( \eqtmR{\ell}{\Gamma}{u}{u'}{A'}{\Type_i} \).
    \end{itemize}
  \item \( \tytmR{\mathsf{Id}}{\Gamma}{e}{A}{\Type_i} \) if there is a normal form \( e' \) such that
    \( \redT{\Gamma}{e}{e'}{\Id{A'}{t}{u}} \) and \( \idtmR{\Gamma}{e'} \), which is defined by
    \begin{mathpar}
      \inferrule{ }
                {\idtmR{\Gamma}{\id{t}}}
      \and
      \inferrule{\tytm{\Gamma}{e}{\Obseq[A']{t}{u}}}
                {\idtmR{\Gamma}{\idpath{e}}}
      \and
      \inferrule{\tytm{\Gamma}{n}{\Id{A'}{t}{u}}
                \\ \text{\( n \) is neutral}}
                {\idtmR{\Gamma}{n}}
    \end{mathpar}
  \item \( \eqtmR{\mathsf{Id}}{\Gamma}{e}{f}{A}{\Type_i} \) if there are normal forms \( e', f' \) such that
    \( \redT{\Gamma}{e}{e'}{\Id{A'}{t}{u}} \) and \( \redT{\Gamma}{f}{f'}{\Id{A'}{t}{u}} \), and
    \( \ideqR{\Gamma}{e'}{f'} \), which is inductively defined by
    \begin{mathpar}
      \inferrule{ }
                {\ideqR{\Gamma}{\id{t}}{\id{t}}}
      \and
      \inferrule{\tytm{\Gamma}{e, f}{\Obseq[A']{t}{u}}}
                {\ideqR{\Gamma}{\idpath{e}}{\idpath{f}}}
    \end{mathpar}
    \begin{mathpar}
      \inferrule{\eqtm{\Gamma}{n}{m}{\Id{A'}{t}{u}}
                \\ \text{\( n, m \) are neutral}}
                {\ideqR{\Gamma}{n}{m}}
    \end{mathpar}
  \end{itemize}

Which states that a term is a reducible witness of the inductive equality when it
reduces to either reflexivity, \( \metaop{Idpath} \), or a neutral term.

\subsection{Reducibility for the Proof-Irrelevant Layer}

We now turn to the definition of reducibility for the proof-irrelevant
fragment, which must be defined independently from the rest of the model
to ensure a well-founded definition.

Since there is no computation whatsoever in proof-irrelevant types,
their inhabitants do not interact with other terms. This allows us
to give a generic definition for reducibility of terms and term
equality, that will work for any \( X \in \{ \mathrm{ne}, \bot, {\Pi \mathsf{i}}\} \) :
%
\begin{itemize}
  \item \( \tytmR{X}{\Gamma}{t}{A}{\sProp}\ \) when \(\ \tytm{\Gamma}{t}{A} \).
  \item \( \eqtmR{X}{\Gamma}{t}{u}{A}{\sProp}\ \) when \(\ \tytm{\Gamma}{t}{A} \) and \( \tytm{\Gamma}{u}{A} \).
  \end{itemize}
%
which means that if \( A \) is in \( \sProp \), then the model does not
need to collect any information on inhabitants of
\( A \), save for the fact that they are well-typed. And this applies
to reducible equality too, for any two inhabitants of \( A \) are always
convertible.
% 
It only remains to define the reducibility of types and type equality
for neutrals, $\Empty$ and the impredicative dependent products.

\paragraph{Proof-irrelevant Neutral Types}

% The first kind of reducible type are neutral type.
\[
  \inferrule{\redT{\Gamma}{A}{N}{\sProp} \\ \neutral{N}}
  {\tytyR{\mathsf{ne}}{\Gamma}{A}{\sProp}}
\]
When $A$ is reducible to a neutral proposition, we define 
reducible equality to \( A \) just as in the case of neutral 
proof-relevant types: 
\( \eqtyR{\mathsf{ne}}{\Gamma}{A}{B}{\sProp} \) if there is 
a neutral term \( M \) such that \( \redT{\Gamma}{B}{M}{\sProp} \) 
and \( \eqtm{\Gamma}{N}{M}{\sProp} \).

\paragraph{Empty type}

The case of the empty type is easy, as it does not recursively call
the logical relation.
\[
{\small
  \inferrule{\redT{\Gamma}{A}{\Empty}{\sProp}}
            {\Gamma \Vdash_{\bot} A}
          }\]
%
        When $A$ is reducible to the empty type, we define
        \( \Gamma \Vdash_{\bot} A \equiv B \) as \( \redT{\Gamma}{B}{\Empty}{\sProp} \).


\paragraph{Impredicative Dependent Function Types}

For the impredicative function types, the situation is more complex,
as we cannot reproduce the definition of their predicative
counterpart:
it involves a recursive call to the logical relation for the domain
and codomain types, which might live in a higher universe than the
function type.
%
Consequently, we go for minimalism and only collect the fact that the domain
and the codomain are well-typed.

  \[
  \inferrule{\redT{\Gamma}{A}{\Depfunannotated{F}{G}{}{\Univ}{\sProp}}{\sProp}
            \\ \tytm{\Gamma}{F}{\Type{}}
            \\ \tytm{\extctx{\Gamma}{F}}{G}{\sProp}}
            {\Gamma \Vdash_{\Pi \mathsf{i}} A}
  \]\label{def:reducibility-impred-pi}
%
Similarly, when $A$ is reducible to an impredicative function type,
% Given a derivation \( \metatm{\mathscr{A}}{\tytyR{\ell}{\Gamma}{A}}
% \) built by this rule,
we define reducible equality of $A$ and $B$ as the fact that $B$
reduces to a convertible impredicative function type:
  \[
  \inferrule{ \redT{\Gamma}{B}{\Depfun{F'}{G'}}{\sProp}
            \\  \eqtm{\Gamma}{\Depfun{F}{G}}{\Depfun{F'}{G'}}{\sProp}}
            {\Gamma \Vdash_{\Pi \mathsf{i}} A \equiv B}
  \]
        %

These definitions do not recursively call the logical relation,
but as a result the collected invariants are
much weaker than those for relevant dependent function
types. We will discuss this in the proof of the fundamental lemma in \cref{sec:fundamental-lemma}.

\paragraph{The Impredicative Universe}
\[
  \inferrule{\redT{\Gamma}{A}{\sProp}{\Type_0}}
            {\Gamma \Vdash_{\Omega} A}
\]
When $A$ is reducible to the impredicative universe, we define:
\begin{itemize}
  \item \( \eqtyR{\Omega}{\Gamma}{A}{B}{\Type_0} \) if \( \redT{\Gamma}{B}{\sProp}{\Type_0} \).
  \item \( \tytmR{\Omega}{\Gamma}{t}{A}{\Type_0} \) if there is a normal form \( t' \) such that
    \( \redT{\Gamma}{t}{t'}{\sProp} \), and \( \tytyR{X}{\Gamma}{t}{\sProp} \) for some
    \( X \in \{ \mathrm{ne}, \bot, {\Pi \mathsf{i}}\} \).
  \item \( \eqtmR{\Omega}{\Gamma}{t}{u}{A}{\Type_0} \) if there are normal forms \( t', u' \), as well
  as \( X \in \{ \mathrm{ne}, \bot, {\Pi \mathsf{i}}\} \) such that
    \begin{itemize}
    \item \( \redT{\Gamma}{t}{t'}{\sProp} \) and \( \redT{\Gamma}{u}{u'}{\sProp} \)
    \item \( \tytyR{X}{\Gamma}{t}{\sProp} \) and \( \tytyR{X}{\Gamma}{u}{\sProp} \)
    \item  \( \eqtyR{X}{\Gamma}{t}{u}{\sProp} \).
    \end{itemize}
\end{itemize}
Being a reducible proposition amounts to reducing to either a neutral term,
the false proposition, or an impredicative dependent product.

\subsection{Auxiliary Lemmas on Reducibility}

Now that we have completed our definition of reducibility, we prove
some auxiliary lemmas:

\begin{lemma}[Escape lemma] \phantom{a}
  \begin{enumerate}
    \item If \( \tytmR{\ell}{\Gamma}{t}{A}{\Univ} \) then \( \tytmannotated{\Gamma}{t}{A}{\Univ} \).
    \item If \( \eqtmR{\ell}{\Gamma}{t}{u}{A}{\Univ} \) then \( \eqtmannotated{\Gamma}{t}{u}{A}{\Univ} \).
  \end{enumerate}
\end{lemma}

\begin{lemma} \phantom{a}
  \begin{enumerate}
  \item Given a context \( \Gamma \), the reducible equality \( \eqtyR{\ell}{\Gamma}{A}{B}{\Univ} \) is
  reflexive, symmetric and transitive. 
  \item Given a context \( \Gamma \) and a reducible type
  \( \tytyR{\ell}{\Gamma}{A}{\Univ} \), the reducible equality \( \eqtmR{\ell}{\Gamma}{t}{u}{A}{\Univ} \)
  is also reflextive, symmetric and transitive.
  \end{enumerate}
\end{lemma}

\begin{lemma}[Conversion]
  Given \( \eqtyR{\ell}{\Gamma}{A}{B}{\Univ} \),
  \begin{enumerate}
    \item \( \tytmR{\ell}{\Gamma}{t}{A}{\Univ} \) if and only if\, \( \tytmR{\ell}{\Gamma}{t}{B}{\Univ} \).
    \item \( \eqtmR{\ell}{\Gamma}{t}{u}{A}{\Univ} \) if and only if\, \( \eqtmR{\ell}{\Gamma}{t}{u}{B}{\Univ} \).
  \end{enumerate}
\end{lemma}

\begin{lemma}[Neutrals are reducible] Let \( A \) be a reducible type and \( n, m \) be neutral terms.
  \begin{enumerate}
    \item If\, \( \tytm{\Gamma}{n}{A} \), then \( \tytmR{\ell}{\Gamma}{n}{A}{\Univ} \).
    \item If\, \( \eqtm{\Gamma}{n}{m}{A} \), then \( \eqtmR{\ell}{\Gamma}{n}{m}{A}{\Univ} \).
  \end{enumerate}
\end{lemma}

\begin{lemma}[Weak head expansion] \phantom{a}
  \begin{enumerate}
    \item If\, \( \tytyR{\ell}{\Gamma}{B}{\Univ} \) and \( \red{\Gamma}{A}{B}{\Univ} \),
      then \( \tytyR{\ell}{\Gamma}{A}{\Univ} \) and \( \eqtyR{\ell}{\Gamma}{A}{B}{\Univ} \).
    \item If\, \( \tytmR{\ell}{\Gamma}{u}{A}{\Univ} \) and \( \red{\Gamma}{t}{u}{A} \),
    then \( \tytmR{\ell}{\Gamma}{t}{A}{\Univ} \) and \( \eqtmR{\ell}{\Gamma}{t}{u}{A}{\Univ} \).
  \end{enumerate}
\end{lemma}

All these lemmas are proved by a straightforward induction. The interested reader can find
formal proofs in \refAgda{LogicalRelation.}{Properties}.

\subsection{Building a Model From Reducibility}
\label{sec:validity}

While reducibility is the main ingredient to our normalization proof, it is not 
strong enough to define a model of \SetoidCC. For instance, reducibility is not 
preserved by the lambda-abstraction rule~\nameref{inferrule:pi-intro}:
\[
	\inferrule[Fun-Rel]
		{\tytmannotated{\extctxannotated{\Gamma}{A}{\Univ}}{t}{B}{\Type_i}}
		{\tytmannotated{\Gamma}{\lam{A}{t}}{\Depfunannotated{A}{B}{\Univ}{\Univ}{\Type_i}}{\Type_{\mathrm{max}(i, \Univ)}}}
\]
For the lambda-abstraction to be a reducible element of the dependent product,
% 
\sideremark{We use the weak-head expansion lemma to reduce the proof of 
reducibility of \( {(\lam{A}{t})\ a} \) to a proof of reducibility of
\( {\subst{t}{a}} \)}
% 
we need to prove that for any term \( a \) which is a reducible inhabitant of
\( A \), the term \( {\subst{t}{a}} \) is a reducible inhabitant of 
\( {\subst{B}{a}} \).
%  
But our induction hypothesis only provides that \( t \) is reducible, and we 
have no obvious way to show that reducibility is stable under substitution by
reducible terms.

Thus, following \sidecitet{Abel:POPL2018}, we define 
the notion of \emph{validity}, which is the closure of reducibility under substitution 
\refAgda{LogicalRelation.}{Substitution}. 
% 
Validity consists of seven predicates.
\begin{itemize}
\item The unary predicate on substitutions \( \substV{\Delta}{\_}{\Gamma} \) 
defines \emph{valid substitutions} from \( \Delta \) to \( \Gamma \) as telescopes
of reducible terms. 
\sideremark{We write \( \Delta \to \Gamma \) for the type of substitutions from
\( \Delta \) to \( \Gamma \). Given a substitution \( \sigma \) and a term 
\( t \), we can substitute the free variables of \( t \) to produce the term
\( t[\sigma] \).}
\item The binary predicate on substitutions \( \eqsubstV{\Delta}{\_}{\_}{\Gamma} \) 
defines \emph{valid equality} of substitutions from \( \Delta \) to \( \Gamma \) as
telescopes of reducible equalities.
\item The unary predicate on terms \( \tytyV{\ell}{\Gamma}{\_}{\Univ} \) defines
\emph{valid types} of sort \( \Univ \) in a context \( \Gamma \) as types that are 
reducible under any valid substitution, and that preserve valid equality of
substitutions.
\item The binary relation on terms \( \eqtyV{\ell}{\Gamma}{\_}{\_}{\Univ} \), 
defines \emph{valid equality} between two valid types in context \( \Gamma \) as
reducible equality under any valid substitution.
\item The unary predicate on terms \( \tytmV{\ell}{\Gamma}{\_}{A}{\Univ} \) 
defines \emph{valid inhabitants} of a valid type \( A \) in context \( \Gamma \) as
terms that are reducible inhabitants of \( A \) under any valid substitution,
and that preserve valid equality of substitutions.
\item The binary relation on terms \( \eqtmV{\ell}{\Gamma}{\_}{\_}{A}{\Univ} \) 
defines \emph{valid equality} between two valid inhabitants of a valid type \( A \) in 
context \( \Gamma \) as reducible equality under any valid substitution.
\item The unary predicate on contexts \( \ctxV{\_} \), defines \emph{valid contexts},
as lists of valid types.
\end{itemize}

\begin{figure*}
  \begin{small}
  \begin{flalign*}
  \begin{array}{lcl}
    \ctxV{\_} & :       & (\Gamma : \Context) \to \AgdaSet{} \\
    \ctxV{\_} & \bnfis  & \emptyctxV\ :\ {\ctxV{\emptyctx}} \\
              & \sep    & \extctxVname\ :\ ([\Gamma] : \ctxV{\Gamma}) \to
                          \tytyV{\ell}{\Gamma}{A}{\Univ} \to \ctxV{\extctxannotated{\Gamma}{A}{\Univ}}
  \end{array} &&
  \end{flalign*}

  % Validity of types
  \begin{flalign*}
  \begin{array}{lcl}
  \tytyV{\ell}{\_}{\_}{\_} & : & (\Gamma : \Context) \to (A : \Term) \to (\Univ : \Sort) \to \{ \ctxV{\Gamma} \} \to \AgdaSet{} \\
  \tytyV{\ell}{\Gamma}{A}{\Univ} & = & \forall\ \sigma\ \tau \to \substV{\Delta}{\sigma}{\Gamma}
                   \ \to\  \tytyR{\ell}{\Delta}{A[\sigma]}{\Univ} \\
                   & & \times\quad \eqsubstV{\Delta}{\sigma}{\tau}{\Gamma}
                   \ \to\ \eqtyR{\ell}{\Delta}{A[\sigma]}{A[\tau]}{\Univ}
  \end{array} &&
  \end{flalign*}

  % Validity of substitutions
  \begin{flalign*}
  \begin{array}{lcl}
  \substV{\_}{\_}{\_} & : & (\Gamma\ \Delta : \Context) \to (\sigma : \Delta \to \Gamma) \to \{ \ctxV{\Gamma} \} \to \AgdaSet{} \\
  \substV{\Delta}{\sigma}{\emptyctx} & = & {\textcolor{AgdaDatatype} \top} \\
  \substV{\Delta}{t, \sigma}{(\extctxannotated{\Gamma}{A}{\Univ})} & = &
                   \substV{\Delta}{\sigma}{\Gamma}
                   \enskip \times \enskip \tytmR{\ell}{\Delta}{t}{A[\sigma]}{\Univ}
  \end{array} &&
  \end{flalign*}

  \begin{flalign*}
  \begin{array}{lcl}
  \eqsubstV{\_}{\_}{\_}{\_} & : & (\Gamma\ \Delta : \Context) \to (\sigma\ \tau : \Delta \to \Gamma) \to \{ \ctxV{\Gamma} \} \to \AgdaSet{} \\
  \eqsubstV{\Delta}{\sigma}{\tau}{\emptyctx} & = & {\textcolor{AgdaDatatype} \top} \\
  \eqsubstV{\Delta}{t, \sigma}{u, \tau}{(\extctxannotated{\Gamma}{A}{\Univ})} & = &
                   \eqsubstV{\Delta}{\sigma}{\tau}{\Gamma}
                   \enskip \times \enskip \eqtmR{\ell}{\Delta}{t}{u}{A[\sigma]}{\Univ}
  \end{array} &&
  \end{flalign*}
  \end{small}

  \caption{Inductive recursive definition of validity of contexts, types and substitutions}
  \label{fig:validity-indrec}
\end{figure*}

In \cref{fig:validity-indrec}, we use induction recursion to define a 
valid context inductively as a telescope of valid types; while we 
simultaneously define valid types, valid substitutions and 
valid equality of substitutions by recursion on a valid context.
% 
The valid type equality, valid terms and valid term equality do not need to be 
part of the inductive-recursive block and can be defined \textit{a posteriori}
in a straightforward manner---see \refAgda{LogicalRelation.}{Substitution}.

\subsection{The Fundamental Lemma}
\label{sec:fundamental-lemma}

The fundamental lemma is the proof that validity is preserved by all inference 
rules of \SetoidCC, or equivalently, that validity defines a model of 
\SetoidCC.

\begin{lemma}[Fundamental lemma for terms
  \refAgda{LogicalRelation.}{Fundamental}]
  \label{thm:fundamental}
  \
  If\, \( \tytmannotated{\Gamma}{t}{A}{\Univ} \), then there is a level \( \ell \) such that $\ctxV{\Gamma}$,
  \( \tytyV{\ell}{\Gamma}{A}{\Type{}} \) and \( \tytmV{\ell}{\Gamma}{t}{A}{\Type{}} \).
\end{lemma}

The lemma is proved by a mutual induction on derivations for well-formed 
contexts, types, type equality, terms and term equality. 
% 
Our various extensions of the model require numerous changes to the proof of 
Abel \etal, but most of these do not pose any major difficulty---although the 
proof is by no means trivial, as the arguments have to be spelled out in
excruciating detail.

Therefore, we focus on the three features of \SetoidCC that are the most
disruptive: the observational equality, the \( \castName \) operator, and
the impredicative dependent products 
(Rules \nameref{inferrule:eq-form}, \nameref{inferrule:cast}, and \nameref{inferrule:pi-irr-form}).

\begin{lemma}[Reducibility of cast]\label{reducibilitycast}
Given any level \( \ell \), in a well-formed context \( \Gamma \), if:
  \begin{enumerate}
    \item \( \tytyR{\ell}{\Gamma}{A}{\Univ} \) and \( \tytyR{\ell}{\Gamma}{A'}{\Univ} \) and \( \eqtyR{\ell}{\Gamma}{A}{A'}{\Univ} \)
    \item \( \tytyR{\ell}{\Gamma}{B}{\Univ} \) and \( \tytyR{\ell}{\Gamma}{B'}{\Univ} \) and \( \eqtyR{\ell}{\Gamma}{B}{B'}{\Univ} \)
    \item \( \tytm{\Gamma}{e}{\Obseq[\Univ]{A}{B}} \) and \( \tytm{\Gamma}{e'}{\Obseq[\Univ]{A'}{B'}} \)
    \item \( \tytmR{\ell}{\Gamma}{t}{A}{\Univ} \) and \( \tytmR{\ell}{\Gamma}{t'}{A'}{\Univ} \) and \( \eqtmR{\ell}{\Gamma}{t}{t'}{A}{\Univ} \)
  \end{enumerate}
  then \( \tytmR{\ell}{\Gamma}{\cast{A}{B}{e}{t}}{B}{\Univ} \) and \\ \( \eqtmR{\ell}{\Gamma}{\cast{A}{B}{e}{t}}{\cast{A'}{B'}{e'}{t'}}{B}{\Univ} \).
\end{lemma}
\sideremark{Note that we are able to prove this lemma on reducibility, without needing validity. 
  It is easy to derive the same lemma for validity once it is established for reducibility.}
\begin{proof}
The proof is by case analysis on the reducibility proofs of \( A, A', B \) and \( B' \).
%
From the proofs of reducible equality, one obtains that the reducibility proofs of \( A \) and
\( A' \) (resp. \( B \) and \( B' \)) are introduced by the same rule. Then, if one of the
normal forms is neutral, or if the normal forms of \( A \) and \( B \) have different head
constructors, then \( \cast{A}{B}{e}{t} \) and \( \cast{A'}{B'}{e'}{t'} \) are neutral and easily
seen to be reducible.
%
Therefore, it suffices to prove the lemma when all the reducibility proofs are introduced by the
same rule. We only cover the case of dependent products, as it is the most interesting.

We know that \( A \) reduces to a term of the form \( \Depfun{F_A}{G_A} \), as do \( A', B, B' \).
Therefore, we know that \( \cast{A}{B}{e}{t} \) reduces to
\( \lam[a']{F_B}{\cast{\subst{G_A}{a}}{\subst{G_B}{a'}}{\snd{e}\ a'}{t\ a}} \) where \( a \) is
a shorthand for \( \cast{F_B}{F_A}{\sym{\fst{e}}}{a'} \), and \( \cast{A'}{B'}{e'}{t'} \) reduces
similarly. By the weak head expansion lemma, it suffices to prove that these two normal forms are
reducible, and reducibly equal at type \( \Depfun{F_B}{G_B} \)---that is, we need to prove that
\begin{itemize}
\item applying either function to a reducible term results in a reducible term,
\item applying the two functions to the same reducible term results in two reducibly equal terms,  
\item and that applying either function to two reducibly equal terms produces two reducibly equal terms.
\end{itemize}

To prove the first obligation, we first recursively apply the lemma to
\( \cast{F_B}{F_A}{\sym{\fst{e}}}{a'} \) so that we obtain reducibility of \( a \), and then
recursively apply it to \( \cast{\subst{G_A}{a}}{\subst{G_B}{a'}}{\snd{e}\ a'}{t\ a} \).
The other two obligations are proved in the exact same manner.
\end{proof}

\begin{lemma}[Reducibility of the observational equality in the universe]\label{reducibilityidU}
  Given any level \( \ell \), in a well formed context \( \Gamma \), if:
    \begin{enumerate}
      \item \( \tytyR{\ell}{\Gamma}{A}{\Univ} \) and \( \tytyR{\ell}{\Gamma}{A'}{\Univ} \) and \( \eqtyR{\ell}{\Gamma}{A}{A'}{\Univ} \)
      \item \( \tytyR{\ell}{\Gamma}{B}{\Univ} \) and \( \tytyR{\ell}{\Gamma}{B'}{\Univ} \) and \( \eqtyR{\ell}{\Gamma}{B}{B'}{\Univ} \)
    \end{enumerate}
    then \( \tytyR{\ell}{\Gamma}{\Obseq[\Univ]{A}{B}}{\sProp} \) and 
    \( \eqtyR{\ell}{\Gamma}{\Obseq[\Univ]{A}{B}}{\Obseq[\Univ]{A'}{B'}}{\sProp} \).
\end{lemma}
\begin{proof}
The proof is by case analysis on the reducibility proofs of \( A, A', B \) and \( B' \). 
As in the proof of \cref{reducibilitycast},
we reduce the proof to introduction rules that correspond to the same kind of normal form.
Most cases are straightforward, the most interesting case being again the dependent products.

We know that \( A \) reduces to a term of the form \( \Depfun{F_A}{G_A} \),
and so for \( A', B\) and \( B' \). Thus, we know that \( \Obseq[\Univ]{A}{B} \) reduces to
\( \Exists[e]{\Obseq[{\Univ}]{F_A}{F_B}}{\Depfun[a']{F_B}{\Obseq[{\Univ}]{\subst{G_A}{a}}{\subst{G_B}{a'}}}} \)
where \( a \) is a shorthand for \( \cast{F_B}{F_A}{\sym{\fst{e}}}{a'} \), and \( \Obseq[\Univ]{A'}{B'} \)
reduces similarly. By the weak head expansion lemma, it suffices to prove that the first normal form
is reducible, and reducibly equal to the second one.
%
We do this by applying reducibility of \( \castName \) to get reducibility of \( a \), and then doing
recursive calls on \( \Obseq[{\Univ}]{F_A}{F_B} \) and
\( \Obseq[{\Univ}]{\subst{G_A}{a}}{\subst{G_B}{a'}} \).
\end{proof}

\begin{lemma}[Reducibility of the observational equality]
  Given any level \( \ell \), in a well formed context \( \Gamma \), if:
    \begin{enumerate}
      \item \( \tytyR{\ell}{\Gamma}{A}{\Type_i} \) and \( \tytyR{\ell}{\Gamma}{A'}{\Type_i} \) and \( \eqtyR{\ell}{\Gamma}{A}{A'}{\Type_i} \)
      \item \( \tytmR{\ell}{\Gamma}{t}{A}{\Type_i} \) and \( \tytmR{\ell}{\Gamma}{t'}{A'}{\Type_i} \) and \( \eqtmR{\ell}{\Gamma}{t}{t'}{A}{\Type_i} \)
      \item \( \tytmR{\ell}{\Gamma}{u}{A}{\Type_i} \) and \( \tytmR{\ell}{\Gamma}{u'}{A'}{\Type_i} \) and \( \eqtmR{\ell}{\Gamma}{u}{u'}{A}{\Type_i} \)
    \end{enumerate}
    then \( \tytyR{\ell}{\Gamma}{\Obseq[A]{t}{u}}{\sProp} \) and \( \eqtyR{\ell}{\Gamma}{\Obseq[A]{t}{u}}{\Obseq[A]{t'}{u'}}{\sProp} \).
\end{lemma}
\begin{proof}
  By case analysis on \( A \) and \( A' \). The most difficult case is the universe, and
  is handled by \cref{reducibilityidU}. The case of dependent products requires doing
  recursive calls on the domain and the codomain, as in the previous lemmas.
\end{proof}

The lemmas for \( \castName \) and the observational equality constitute the 
bulk of the proof: they occupy approximately 5,000 lines of Agda
code and most of the time required to check the whole proof is spent on them.

\begin{lemma}
  The rules \nameref{inferrule:pi-irr-form}, \nameref{inferrule:pi-irr-intro} and \nameref{inferrule:pi-irr-elim} preserve validity.
\end{lemma}

\begin{proof}
  The case of the formation rule \nameref{inferrule:pi-irr-form} is easy, as 
  proving reducibility of a proof-irrelevant \( \Pi \)-type only requires 
  proving that the domain and codomain are well-typed, which we obtain from 
  the validity hypotheses.

  The case of the lambda-abstraction rule \nameref{inferrule:pi-irr-intro} is 
  also a one-liner, because proving reducibility of an inhabitant of a 
  proof-irrelevant type is only a matter of showing that it is well-typed.

  The case of the elimination rule \nameref{inferrule:pi-irr-elim} is more 
  interesting: the conclusion needs us to prove that \( \subst{B}{u} \) is
  a valid proposition for any valid inhabitant \( u : A \), and then that
  \( t\ u \) is well-typed.
  % 
  Unfortunately, it seems that the premises give us very little information 
  on \( B \), because our definition of reducibility for impredicative dependent
  products is very weak (definition \ref{def:reducibility-impred-pi}).
  % 
  We circumvent this problem by replacing rule \nameref{inferrule:pi-irr-elim}
  with the following typing rule, which adds well-formedness hypotheses for
  the domain and codomain of the \( \Pi \)-type.
  % 
  \sideremark{Even though this change of rules gives the impression that the
    economic rules we presented in \cref{ch:observational} omit essential premises, 
    it is in fact not the case. 
    In \cref{sec:remov-paran-prem}, we will show that the economic rules contain 
    sufficient information to recover all the necessary premises.}
  % 
  \[
    \inferrule[App-Irr']{\tytm{\Gamma}{A}{\Univ} \\
    \tytm{\extctxannotated{\Gamma}{A}{\Univ}}{B}{\sProp}
    \\
    \tytmannotated{\Gamma}{t}{\Depfun{A}{B}}{\sProp}
            \\ \tytmannotated{\Gamma}{u}{A}{\Univ}}
            {\tytmannotated{\Gamma}{t\ u}{\subst{B}{u}}{\sProp}}
  \]
  Now, our hypotheses also provide that $B$ is valid as a type family over $A$. 
  Since validity is defined as reducibility under any valid substitution, we can 
  get the reducibility of ${\subst{B}{u}}$.
\end{proof}

This concludes our overview of the proof of the fundamental lemma. As a direct
consequence, we obtain that any well-typed term is reducible, and thus 
normalizing:

\begin{corollary}[Normalization]
  Any well-typed term has a weak-head normal form.
\end{corollary}

\section{Consequences of Normalization}
\label{sec:normalization-consequences}

\subsection{Canonicity}

A direct consequence of the fundamental lemma is that any closed
term of type $\Nat$ reduces to a whnf of type $\Nat$. Thus, to
derive canonicity for the natural numbers, we just need to know that there are
no neutral terms of type $\Nat$ in an empty context.

In \MLTT, neutral terms necessarily contain a variable, and therefore cannot 
exist in the empty context. 
% 
But unfortunately, the situation is more delicate for \SetoidCC, as
the eliminator \( \metaop{\Empty-elim} \) can produce a neutral term from any 
proof of \( \Empty \), over which reducibility does not provide any control.
% 
Moreover, the \( \castName \) operator can produce a neutral term from any
proof of observational equality between two types with incompatible head 
constructors, which we do not control either.

Therefore, in order to prove canonicity for natural numbers (or for any other 
type), we need to show that there exists no proof of \( \Empty \) in the empty
context, and no proof of equality between incompatible types.
%
We will prove this by constructing a set-theoretic model of \SetoidCC in 
\cref{sec:cons-seto-model}. As a consequence, we are able to derive our 
canonicity theorem:

\begin{theorem}[Computational canonicity of \( \Nat \)]
	If a term \( t \) has type \( \Nat \) in the empty context, then there 
	exists an external integer \( n \) such that \( t \) reduces to 
  \( \metaop{S}^n\ \zero \).
\end{theorem}

This strategy of deriving canonicity from consistency and normalization was 
already envisioned by Altenkirch \etal~\sidecite{AltenkirchMcBrideSwiestra07}.

\subsection{Decidability of Conversion}

In order to prove that convertibity is decidable for \SetoidCC, we need to 
devise a conversion checking algorithm, and then prove that it is both
correct and complete.

To do so, we follow \sidecitet{Abel:POPL2018} and define 
\emph{algorithmic conversion} as a relation 
$\algoeqtmannotated{\Gamma}{t}{u}{A}{\Univ}$ between two well-typed 
terms \( t \) and \( u \) of type \( A \) in context \( \Gamma \).
%
This algorithmic conversion keeps track of the relevance information,
and uses it to either give an immediate answer in case \( t \) and
\( u \) are irrelevant, or to compute their weak-head normal forms using
the normalization theorem, then compare their head constructor, and possibly 
apply the algorithm recursively in case \( t \) and \( u \) are relevant.
%
Correctness of this algorithmic conversion is direct as the rules used are
subsumed by the general conversion judgement \refAgda{Conversion.}{Soundness}.

Showing that the algorithmic conversion is also complete is more involved.
%
The main ingredient is more or less a re-enactment of our proof of the 
fundamental lemma, but with a definition of reducibility that
uses algorithmic conversion instead of the definitional equality of \SetoidCC.
\refAgda{Conversion.Consequences.}{Completeness}.
%
In our formal proof, we follow \sidecitet{Abel:POPL2018} in factoring the two
instances of the fundamental lemma by defininig a generic interface for both
algorithmic conversion and typed conversion, and using this interface
in the definition of the logical relation \refAgda{Typed.}{EqualityRelation}.

\begin{theorem}[Equivalence of conversion and algorithmic conversion]
  \label{thm:algoconv}
    Given two terms $t$ and $u$ such that
    $\tytmannotated{\Gamma}{t}{A}{\Univ}$ and
    $\tytmannotated{\Gamma}{u}{A}{\Univ}$, we have that
    $$ \eqtmannotated{\Gamma}{t}{u}{A}{\Univ} \Longleftrightarrow\algoeqtmannotated{\Gamma}{t}{u}{A}{\Type{}}.$$
\end{theorem}

It still remains to provide a decision procedure for the algorithmic
conversion \refAgda{Conversion.}{Decidable}.
%
Given two terms $t$ and $u$ well-typed at $A : \Univ$ in context
$\Gamma$, we can apply the fundamental lemma plus the reflexivity of
the logical relation to get the fact that $\eqtmR{\ell}{\Gamma}{t}{t}{A}{\Univ}$
and similarly for $u$.
%
Because reducibly equal terms are also algorithmically convertible by the escape lemma, we
have $\algoeqtmannotated{\Gamma}{t}{t}{A}{\Univ}$ (and similarly for $u$).
%
Then the decision procedure is done by double induction on the proofs
that $t$ and $u$ are reflexive for the algorithmic conversion.
%
The idea is that $t$ and $u$ are convertible if and only if the two reflexive proofs are the same.

Note that the proof that $t$ is algorithmically equal to itself
contains the fact that $t$ strongly normalizes, because
$t$ can be recursively put in whnf.

\subsection{Decidability of Typing}
\label{sec:decidable-typing}

Now that we have an algorithm that decides conversion, we can rely on the
work of \sidecitet{meven_thesis} on bidirectional type-checking, who explains 
how to obtain an algorithm for type-checking provided that the
theory enjoys subject reduction and decidability of conversion.

% \shepherd{TODO if I have time left: an overview of bidirectional type checking?? probably a bad idea lol}

\subsection{Inferring Premises from Economic Typing Rules}

Recall that in our construction of the normalization model, impredicativity 
forced us to give a definition of reducibility for proof-irrelevant 
\( \Pi \)-types that is considerably weaker than the definition for 
proof-relevant \( \Pi \)-types.
% 
As a consequence, we were not able to prove the fundamental lemma 
directly on the economic inference rules of \cref{ch:observational}, and we
circumvented this issue by adding well-formedness hypotheses to several
rules. For instance, the rule for application of a proof-irrelevant function
\[
\inferrule[App-Irr]
{\tytmannotated{\Gamma}{t}{\Depfun{A}{B}}{\sProp}
  \\ \tytmannotated{\Gamma}{u}{A}{\Univ}}
{\tytmannotated{\Gamma}{t\ u}{\subst{B}{u}}{\sProp}}
\]
was modified to include hypotheses on the domain and the codomain
of the function.
\[
  \inferrule[App-Irr']{\tytm{\Gamma}{A}{\Univ} \\
  \tytm{\extctxannotated{\Gamma}{A}{\Univ}}{B}{\sProp}
  \\
  \tytmannotated{\Gamma}{t}{\Depfun{A}{B}}{\sProp}
          \\ \tytmannotated{\Gamma}{u}{A}{\Univ}}
          {\tytmannotated{\Gamma}{t\ u}{\subst{B}{u}}{\sProp}}
\]

Therefore, the reader may wonder if the economic rules are only approximations 
which need to be extended with the omitted well-formedness premises for types, 
contexts, etc.
% 
In this section, we show that it is not the case, and that the economic 
rules are in fact equivalent to the full rules.

\sideremark{The terminology is in reference to Bauer \etal \cite{andrej17:paranoid}.}
% 
Until the next section, we distinguish between the \emph{economic} version of the 
system which uses the rules defined in \cref{ch:observational}, that we denote 
\( \vdash_e \), and the \emph{paranoid} version which adds well-formedness
hypotheses to all types that appear in rules, noted \( \vdash_p \).

Obviously, when a term is well-typed for the paranoid variant, it is
also well-typed in the economic system. But after proving the
fundamental lemma on the paranoid variant, it becomes possible to show
that the two typing systems are equivalent, leveraging the inversion
lemmas provided by reducibility.
%
\sideremark{It must be noted that since the proof of equivalence of the
two systems uses the fundamental lemma, it is by no means computationally
trivial. Therefore, in an actual implementation of a typechecker for 
\SetoidCC, it might be more sensible to work with the paranoid system if 
we need the supplementary information.}
% 
Thus, the additional premises of the paranoid variant help us
prove the fundamental lemma in presence of impredicativity, but end up
being redundant once a sufficient amount of metatheory is established.

First, we establish the following result on the paranoid
typing, by combining the fundamental lemma with the fact that
reducible types are well-formed and reducible terms are well-typed:
%
\begin{corollary}[Typing Validity \refAgda{Typed.Consequences.}{Syntactic}] \label{thm:validity} \phantom{a}
  \begin{enumerate}
    \item If $\tytmParaannotated{\Gamma}{t}{A}{\Univ}$ then $\tytmPara{\Gamma}{A}{\Univ}$ 
    \item If $\eqtmParaannotated{\Gamma}{t}{u}{A}{\Univ}$ then
  $\tytmPara{\Gamma}{A}{\Univ}$,
  $\tytmParaannotated{\Gamma}{t}{A}{\Univ}$ and $\tytmParaannotated{\Gamma}{u}{A}{\Univ}$.
  \end{enumerate}
\end{corollary}
%
And now that we are equipped with this corollary, as well as some
inversion lemmas that we obtained from the reducibility, we know
enough to build a paranoid typing derivation from a
standard derivation:
%
\begin{theorem}[\refAgda{Typed.}{NonParanoidTyping}]
  \label{thm:nonparanoid}
  If $\tytmEcoannotated{\Gamma}{t}{A}{\Univ}$ then $\tytmParaannotated{\Gamma}{t}{A}{\Univ}$.
\end{theorem}
\begin{proof}
  The proof is by induction on the typing derivation. The
  correspondence between the two systems is one-to-one except for the
  additional paranoid assumptions.
  %
  In all cases, we can get them from \cref{thm:validity} and from
  inversion lemmas, such as the fact that $A$ and $B$ are well-typed
  whenever $\Depfun{A}{B}$ is.
\end{proof}

Thus, we also have the fundamental lemma for the economic type system:
%
\begin{corollary}[Fundamental lemma on the economic type system]
  If\, \( \tytmEcoannotated{\Gamma}{t}{A}{\Univ} \), then there is a level \( \ell \) such that $\ctxV{\Gamma}$,
  \( \tytyV{\ell}{\Gamma}{A}{\Univ} \) and \( \tytmV{\ell}{\Gamma}{t}{A}{\Univ} \).
\end{corollary}

\section{Analysis of the Normalization Proof}
\label{sec:analys-norm-proof}

Both the informal normalization proof presented in \cref{sec:logic-relat-with}
and its formalized version in \Agda take place in a somewhat sophisticated metatheory: 
Martin-LÃ¶f Type Theory extended with induction-recursion.
%
In this section, we explain how to re-enact the proof in a weaker meta-theory in 
order to control the computational complexity of the proof terms more finely.

\subsection{The Computational Expressivity of \SetoidCC}

Proof-relevant terms in \SetoidCC are \emph{programs}, at least in the sense of 
being terms in a lambda-calculus with additional operators.
% 
As such, they may be extracted and evaluated just like regular programs---
and in fact, evaluating open terms is pretty much what our type-checking 
algorithm from \cref{sec:decidable-typing} does.
% 
Therefore, it makes sense to investigate the computational complexity of 
these proof terms: which integer functions
% 
\sideremark{We restrict our attention to functions from \( \Nat \) to 
  \( \Nat \), because higher-order computability is a complex topic with many 
  non-equivalent definitions.}
% 
can be expressed as proof terms?

As an aside, we must mention that these considerations are not a useful measure 
of the feasability of type-checking.
% 
Indeed, most proof assistants based on type theory have ridiculously high 
worst-case complexity, but they are still very efficient in practice! 
% 
However, investigating the expressive power of proof terms is still a
worthwile endeavor, as it provides us with information on the kinds of mathematical
statements that can be proved in the proof-relevant fragment of \SetoidCC: for 
instance, is it possible to show normalization of System F?

To derive a lower bound for the computational expressivity, we simply remark 
that Martin-LÃ¶f type theory is a subset of \SetoidCC, provided we use a 
definition of \MLTT that does not support more inductive types than our 
definition of \SetoidCC.
%
Therefore, any function that can be defined in \MLTT is definable in \SetoidCC.

In order to obtain an upper bound, we need to analyze the normalization proof:
since the argument is constructive, it provides us with a concrete algorithm to 
evaluate terms of \SetoidCC. 
% 
Therefore, we seek to replay our normalization proof in a meta-theory that is 
as weak as possible, to get a tighter upper bound. Of course, we cannot
hope to go lower than \MLTT, given that it is a subset \SetoidCC. But we
can get pretty close:

\begin{theorem}\label{setoidCC-in-MLTT}
  \MLTT with \( n + 4 \) universes and \( \mathrm{W} \)-types can prove normalization of 
  \SetoidCC with \( n \) universes and \( \mathrm{W} \)-types.
\end{theorem}
\begin{proof}
  The proof of this theorem is given in \cref{sec:fitt-norm-proof}.
\end{proof}

In the rest of this section, we need to be very precise about the exact
amount of inductives and universes in our theories.
We will write \( \MLTTW_n \) for Martin-LÃ¶f type 
theory with \( n \) universes and \( \mathrm{W} \)-types, and we will write
\( \SetoidCCW_n \) for the observational calculus of constructions extended 
with proof-relevant \( \mathrm{W} \)-types and \( n \) universes.

When we let \( n \) go to infinity, or in other words when we consider theories 
with an unbounded hierarchy of universes, we get that
normalization for \MLTTW is equivalent to normalization for \SetoidCCW.

\begin{corollary}
  Normalization for \SetoidCCW is equivalent to normalization for \MLTTW
  over a weak fragment of arithmetic.
\end{corollary}

Note that we cannot hope for a similar result in terms of consistency or
canonicity: while consistency and canonicity for \MLTTW follow from
normalization, proving that \SetoidCCW is consistent requires an impredicative
theory, which is necessarily much stronger than \MLTTW.

\Cref{setoidCC-in-MLTT} also provides us with a neat description of the
computational power of \SetoidCCW:

\begin{corollary}\label{integer-functions}
  \SetoidCCW and \MLTTW can express the exact same integer functions
  as closed terms of type \( \Fun{\Nat}{\Nat} \).
\end{corollary}

\begin{proof}
  In one direction, we can simply embed functions from \MLTTW into \SetoidCCW.

  In the converse direction, we note that any closed term \( f \) of
  type \( \Fun{\Nat}{\Nat} \) in \SetoidCCW only mentions a finite number of
  universes \( N \).
  %
  Thus, \cref{setoidCC-in-MLTT} provides us with a normalization function for 
  \( \SetoidCCW_N \) in \( \MLTTW_{N+4} \), that computes the normal form of any 
  well-typed term. 
  % 
  From there, we can define a function \( f' : \Fun{\Nat}{\Nat} \) in \MLTTW
  that represents the same integer function as \( f \).
  Given an integer \( n : \Nat \), \( f' \) first computes a \SetoidCCW typing 
  derivation for \( f\ n \) in the empty context, then applies the 
  normalization function to obtain a weak-head normal form that is necessarily
  canonical, and converts this normal form back to an integer.
\end{proof}
%
In the case of \SetoidCC without \( \mathrm{W} \)-types, we only know that its
computational power is between that of \MLTT and \MLTTW, but we conjecture that
it is equivalent to \MLTT.

\Cref{integer-functions} might come off as a surprise, since \SetoidCC is 
equipped with an impredicative universe, and impredicativity generally adds
a great deal of proof-theoretic strength!
%
And \SetoidCC does possess this logical power, in fact. Indeed, it can
represent many more functions as \( \sProp \)-valued functional relations
than \MLTT. But this corollary shows that there is no way to extract them
in the proof-relevant fragment, even though we have access to elimination
principles for false propositions and the observational equality.
%
Thus, the logical power of impredicativity is locked inside of \( \sProp \).

This is in stark contrast with the Calculus of Inductive Constructions,
in which it is possible to define closed terms of type \( \Fun{\Nat}{\Nat} \) that leverage
the power of impredicativity, using a principle called large elimination
of singleton inductive types\sideremark{The standard technique is to use
the accessibility predicate as defined in \url{https://coq.inria.fr/library/Coq.Init.Wf.html}.}.
%
We discuss this principle with more detail in \cref{ch:extensions}.

\subsection{Fitting the Normalization Proof in MLTT}
\label{sec:fitt-norm-proof}

In this section, we give a proof of \cref{setoidCC-in-MLTT}, by
encoding the logical relation sketched in \cref{sec:logic-relat-with}
without induction-recursion.
%
This argument has been formalized in \Agda.\sideremark{The formalization is in the
  folder \texttt{logrel-wo-ind-rec}. It is done for \MLTT and not
full \SetoidCC, but it does not make a difference as the crux of the proof is in
the definition of the relation without induction-recursion.}
%
For the remainder of this section, we work in \( \MLTTW_{n+4} \) with a deep
embedding of \( \SetoidCCW_n \).
% 
Having \( \mathrm{W} \)-types and inductive equalities in our meta-theory,
it becomes possible to encode a wide range of indexed, nested inductive
types as described by \sidecitet{inductives_with_W}. Therefore, we freely
make use of them, and assume they are translated back to \( \mathrm{W} \)-types.
%
To avoid confusion between the meta-theory and the object theory, we
will use \Agda-style notations for the meta-theory.

From a bird's eye perspective, the normalization proof builds a model
of \SetoidCCW in which well-formed types are interpreted as proof-relevant
predicates on untyped terms, and induction-recursion is used to construct a
universe in the model: we define the inductive predicate of reducible types
simultaneously with recursive functions that associates reducibility
predicates to a reducible type.
%
On closer inspection, we realize that the proof still works if the
reducibility predicate of a universe lives one universe higher than the
reducibility predicates of the types it contains. This allows us to use
\emph{small} induction-recursion, which can be replaced by functional
relations that only require simple indexed inductive types
\sidecite{small-ind-rec}.

\Cref{fig:logrel-ind} showcases what the relation-based definition
looks like.
%
For all \( \ell \le n \), we define an inductive relation \( \AgdaData{R}^\ell \) between
a context, an untyped term \( t \) (the reducible type), its sort, a predicate \( P_{=} \) of
types that are convertible to \( t \), a predicate \( P_{t} \) which is the
reducibility predicate associated to \( t \), and a binary relation
\( P_{t=} \) that encodes convertibility of terms in \( P_{t} \).
%
The reducibility for types \( \Vdash_\ell \) is then defined in terms of \( \AgdaData{R}^\ell \).
%
The inductive relation features twelve constructors that are all
described in \cref{sec:logic-relat-with}, except for the \( \mathrm{W} \)-types
(which do not pose any additional difficulty).
%% , plus an eighth one that ensures
%% \( \AgdaData{R}^\ell \) contains all the relations \( \AgdaData{R}^{\ell'} \) for \( \ell' < \ell \).

Note that the logical relation is built in stages:
\begin{itemize}
\item We first define an inductive relation
  \( \AgdaData{R}^0 \) that has cases for dependent products and all base types, except
  for proof-relevant universes: it only accounts for inhabitants of
  \( \Type_0 \).
  %
\item From \( \AgdaData{R}^0 \), we define a reducibility predicate \( P_{\Type_0} \) for
  \( \Type_0 \): a term \( t \) is in \( P_{\Type_0} \) if there exist
  \( P_=, P_t, P_{t=} \) such that \( R^0(t,P_=, P_t, P_{t=}) \).
  %
  Now that we have a predicate for \( \Type_0 \), we can define a relation
  \( \AgdaData{R}^1 \) that accounts for inhabitants of \( \Type_1 \). Of course, since
  \( P_{\Type_0} \) lives in \( \AgdaSet{1} \), \( \AgdaData{R}^1 \) will land in \( \AgdaSet{2} \).
\item We repeat this process \( n \) times to obtain a relation \( \AgdaData{R}^n \)
  that handles our \( n \) universes.
\end{itemize}
Each step of this process requires an additional meta-theoretical universe
level.
%
This is only natural, since we are proving normalization for a theory that
subsumes \( \MLTTW_n \), a property from which we can deduce the consistency
of \( \MLTTW_n \).
%
Therefore, GÃ¶del's incompleteness theorem applies and guarantees that
we need more universes in the meta-theory than in the fragment we
consider.


\begin{figure*}
  \begin{small}
\begin{flalign*}
  \begin{array}{lcl}
   \AgdaData{R}^\ell         & : & \Context \to \Term \to (\Term \to \AgdaSet{\ell}) \to (\Term \to \AgdaSet{\ell}) \to (\Term \to \Term \to \AgdaSet{\ell}) \to \AgdaSet{\ell+1} \\
   \AgdaData{R}^\ell         & \bnfis & \Rne : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\mathsf{ne}} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\mathsf{ne}} t \equiv \_)\ (\Gamma\ \Vdash_{\mathsf{ne}} \_ : t)\ (\Gamma\ \Vdash_{\mathsf{ne}} \_ \equiv \_ : t)\\
               & \sep & \Rforall : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\Pi \mathsf{i}} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\Pi \mathsf{i}} t \equiv \_)\ (\Gamma\ \Vdash_{\Pi \mathsf{i}} \_ : t)\ (\Gamma\ \Vdash_{\Pi \mathsf{i}} \_ \equiv \_ : t)\\
               & \sep & \Rempty : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\bot} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\bot} t \equiv \_)\ (\Gamma\ \Vdash_{\bot} \_ : t)\ (\Gamma\ \Vdash_{\bot} \_ \equiv \_ : t)\\
               & \sep & \RU : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\mathsf{U}} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\mathsf{U}} t \equiv \_)\ (\Gamma\ \Vdash_{\mathsf{U}} \_ : t)\ (\Gamma\ \Vdash_{\mathsf{U}} \_ \equiv \_ : t)\\
               & \sep & \ROmega : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\Omega} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\Omega} t \equiv \_)\ (\Gamma\ \Vdash_{\Omega} \_ : t)\ (\Gamma\ \Vdash_{\Omega} \_ \equiv \_ : t)\\
               & \sep & \Rnat : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\Nat} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\Nat} t \equiv \_)\ (\Gamma\ \Vdash_{\Nat} \_ : t)\ (\Gamma\ \Vdash_{\Nat} \_ \equiv \_ : t)\\
               & \sep & \Rpi : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\Sigma} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\Pi} t \equiv \_)\ (\Gamma\ \Vdash_{\Pi} \_ : t)\ (\Gamma\ \Vdash_{\Pi} \_ \equiv \_ : t)\\
               & \sep & \Rsigma : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\Sigma} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\Sigma} t \equiv \_)\ (\Gamma\ \Vdash_{\Sigma} \_ : t)\ (\Gamma\ \Vdash_{\Sigma} \_ \equiv \_ : t)\\
               & \sep & \Rbox : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\Box} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\Box} t \equiv \_)\ (\Gamma\ \Vdash_{\Box} \_ : t)\ (\Gamma\ \Vdash_{\Box} \_ \equiv \_ : t)\\
               & \sep & \Rquo : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\mathsf{Q}} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\mathsf{Q}} t \equiv \_)\ (\Gamma\ \Vdash_{\mathsf{Q}} \_ : t)\ (\Gamma\ \Vdash_{\mathsf{Q}} \_ \equiv \_ : t)\\
               & \sep & \Rid : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\mathsf{Id}} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\mathsf{Id}} t \equiv \_)\ (\Gamma\ \Vdash_{\mathsf{Id}} \_ : t)\ (\Gamma\ \Vdash_{\mathsf{Id}} \_ \equiv \_ : t)\\
               & \sep & \RW : \forall\ \Gamma\ t \to
                          (\Gamma \Vdash_{\mathsf{Id}} t) \to
                          \AgdaData{R}^\ell\ \Gamma\ t\ (\Gamma\ \Vdash_{\mathsf{W}} t \equiv \_)\ (\Gamma\ \Vdash_{\mathsf{W}} \_ : t)\ (\Gamma\ \Vdash_{\mathsf{W}} \_ \equiv \_ : t)\\
               %% & \sep & \Remb : \forall\ \Gamma\ t\ P_=\ P_t\ P_{t=} \to \AgdaData{R}^{\ell'}\ \Gamma\ t\ P_=\ P_t\ P_{t=} \to \AgdaData{R}^\ell\ \Gamma\ t\ P_=\ P_t\ P_{t=} \qquad \text{for all } \ell' < \ell
  \end{array} &&
\end{flalign*}

\begin{flalign*}
& \text{All the auxiliary predicates whose name mentions } \Vdash_{\mathsf{ne}} \, ,\ \Vdash_{\Pi \mathsf{i}} \, ,\ \Vdash_{\bot} \, , \ \Vdash_{\mathsf{U}}...
\text{ are defined exactly as in \cref{sec:logic-relat-with}.} &
\end{flalign*}

\begin{flalign*}
  \begin{array}{lcl}
\_ \Vdash_\ell \_ : \_ & : & (\Gamma : \Context) \to (t : \Term) \to (A : \Term) \to (s : \Sort) \to \AgdaSet{\ell+1} \\
\Gamma \Vdash_\ell t : s & = & (P_= : \Term \to \AgdaSet{\ell}) \times (P_t : \Term \to \AgdaSet{\ell}) \\ && \times\ (P_{t=} : \Term \to \Term \to \AgdaSet{\ell}) \times (\AgdaData{R}^\ell\ \Gamma\ t\ s\ P_=\ P_t\ P_{t=})
  \end{array} &&
\end{flalign*}

\begin{flalign*}
  \begin{array}{lcl}
\_ \Vdash_\ell \_ \equiv \_ : \_ & : & (\Gamma : \Context) \to (A : \Term) \to (B : \Term) \to (s : \Sort) \to \{ \Gamma \Vdash_\ell A : s \} \to \AgdaSet{\ell} \\
\Gamma \Vdash_\ell A \equiv B : s & = & P_=\ B
  \end{array} &&
\end{flalign*}

\begin{flalign*}
  \begin{array}{lcl}
\_ \Vdash_\ell \_ : \_ : \_ & : & (\Gamma : \Context) \to (t : \Term) \to (A : \Term) \to (s : \Sort) \to \{ \Gamma \Vdash_\ell A : s \} \to \AgdaSet{\ell} \\
\Gamma \Vdash_\ell t : A : s & = & P_t\ t
  \end{array} &&
\end{flalign*}

\begin{flalign*}
  \begin{array}{lcl}
\_ \Vdash_\ell \_ \equiv \_ : \_ : \_ & : & (\Gamma : \Context) \to (t\ u : \Term) \to (A : \Term) \to (s : \Sort) \to \{ \Gamma \Vdash_\ell A : s \} \to \AgdaSet{\ell} \\
\Gamma \Vdash_\ell t \equiv u : A : s & = & P_{t=}\ t\ u
  \end{array} &&
\end{flalign*}
\end{small}
  \caption{Inductive encoding of reducibility}
  \label{fig:logrel-ind}
\end{figure*}

Constructing this universe of reducible types is only the first half
of the normalization proof. To complete the construction, we also need
to encode validity without induction-recursion in \( \MLTTW_{n+4} \) and
prove the fundamental lemma.
%
We do not develop this here as the construction is a similar encoding of
small induction-recursion with functional relations.
The interested reader can consult the formalization for a more detailed proof.

\section{Semantics of \SetoidCC}
\label{sec:cons-seto-model}

In this section, we turn to the construction of the
``standard'' set-theoretic model of \SetoidCC.
%
This model serves two purposes: to show consistency of our theory on
the one hand, and to ensure that \SetoidCC is a good internal language for
set theory on the other hand.

\subsection{Deriving Consistency from a Model}

As we already mentioned, the normalization model that we built in
\cref{sec:logic-relat-with} is not strong enough to obtain consistency
and canonicity for \SetoidCC. Indeed, this model interprets the
proof-irrelevant proposition \( \bot \) as the set of syntactic
terms with type \( \bot \), which does not grant any kind of control
over its proofs in the empty context.

This was already the case in our previous work on \SetoidTT \sidecite{pujet:hal-03367052}, 
so we supplemented our normalization proof with a model
in the category of sets (presented as setoids), using
induction-recursion to interpret universes as sets of codes \textit{Ã 
  la Tarski} defined mutually with eliminators and coercion functions.
%
In that model, \( \bot \) is actually interpreted as the empty set, which
proves consistency of \SetoidTT: we can use it to show that there is
no term of type \( \bot \) in the empty context.

\subsection{\SetoidCC as an Internal Language for Sets}

While the construction from our earlier work \cite{pujet:hal-03367052} does 
show consistency of \SetoidTT, it arguably falls short of presenting \SetoidTT 
as an internal language for classical mathematics.
%
Indeed, the inductive-recursive construction of the universe of codes is
designed to only account for the codes that come from the syntax of
\SetoidTT. In other words, the following statement
\[
\Pi(A : \Type)(x\ y\ z : A).\,\Fun{\Fun{\Obseq[A]{x}{y}}{\Obseq[A]{y}{z}}}{\Obseq[A]{x}{z}}
\]
only states transitivity of equality for sets that are built from
the type formers of \SetoidTT, when interpreted in their model.

This state of affairs is obviously not ideal, as readers who are not
willing to accept \SetoidTT / \SetoidCC as a new foundation of mathematics would
probably be more inclined to use it if they knew that any theorem they
proved in type theory is also true for classical set theory.
%
Thus, instead of replicating this construction in an impredicative
meta-theory (to be able to interpret \( \sProp \)), we seize the
opportunity to solve two problems at once, and present a model in classical
set theory that gives a much more sensible meaning to statements in \SetoidCC
while still being able to show consistency.

\subsection{Constructing the Set-theoretic Model}

We work in ZF set theory with a countable hierarchy of Grothendieck universes
\( \sV_0, \sV_1, ... \)
%
We call \( \Two \) the lattice of truth values (or in other words, the
subobjects of the singleton set \( \{ * \} \)), with \( \emptyset \) as its 
minimal value.
%
Even though we stay in the world of set theory for the duration of
this section, we remain type theorists, and as such
we use dependent products, dependent sums and inductive types in this
section. They should be understood as their standard interpretation in
the set-theoretic model of type theory.
%
In an attempt to minimize confusion, we change our notations a little
bit: we use \( (a \in A) \to (B\ a) \) for the set-theoretic dependent product,
\( (a \in A) \times (B\ a) \) for the the set-theoretic dependent sum and
\( \metanat \) for the set-theoretic integers.

The central ingredient of our standard model is the interpretation of the
proof-relevant universes of \SetoidCC.
%
It is tempting to define them directly as Grothendieck universes, but 
unfortunately this does not work: in \SetoidCC, type constructors are 
injective with respect to the observational equality
(for instance, \( \Obseq{(\Fun{A}{B})}{(\Fun{A'}{B'})} \) implies that
\( \Obseq{A}{A'} \) and \( \Obseq{B}{B'} \)) while set-theoretic function
spaces collapse too much information for this to be possible
(\( \Fun{\bot}{\Bool} \) and \( \Fun{\bot}{\Nat} \) are identical function 
sets).

This is not too difficult to fix, however: 
% 
we can define a hierarchy of sets \( \sU_0 , \sU_1 ... \) that have the same 
elements as the Grothendieck universes, but decorated with labels that keep 
track of how they were constructed. For instance, the label of a set that has 
been constructed as a function space will contain the labels of its domain and 
codomain, so that there is no way to confuse two different function spaces that happen
to have the same elements. 

The most natural way to do this from a type
theorist's perspective is to build an inductive predicate \( \Upred_i \) over
\( \sV_i \) and then define our alternative universes as
\( \sU_i := (X \in \sV_i)\times(\Upred_i\ X) \), as described in \cref{fig:model}.
%
Note how the constructor \( \codeemb \) builds a proof of \( \Upred_i\ X \)
for any (small) set \( X \), so that \SetoidCC statements that quantify over
the universe apply to all appropriately-sized sets of the model.
%
This also implies that there might be several codes for the
same set: for instance \( (\Fun{\Nat}{\Nat} \ ;\ \codeemb) \) and
\( (\Fun{\Nat}{\Nat} \ ;\ \codepiuu\ ...) \) are both codes for
the set \( \Fun{\Nat}{\Nat} \), but only the second one remembers that it
has been built as a function space.

Remark that the natural equality between elements of \( \sU_i \) corresponds 
closely the equality of \SetoidCC: two elements can only be equal if they pack 
the same witness of \( \Upred_i \), which means that they have been built in the 
same way.
% 
Moreover, if we compare two codes of the form \( (X \to Y ;\ \codepiuu\ ...) \), 
the equality of the second member means that the domains and the codomains of 
the function spaces are equal---we recover the injectivity of the type formers.

\begin{figure}
   \begin{small}
\begin{flalign*}
  \begin{array}{lcl}
   \Upred_i         & : & \Fun{\sV_i}{\sV_{i+1}}\\
   \Upred_i         & \bnfis & \tm{\codeemb}{\Fun{(X \in \sV_i)}{\Upred_i\ X}}\\
%                     & \sep & \tm{\codenat}{\sU_i} & \qquad & \text{if i = 0}\\
                     & \sep & \tm{\codepiuu}{\{ j, k \in \metanat\ |\ \mathrm{max}(j, k) \le i\} \to (A \in \sV_j) \to (A_\varepsilon \in \Upred_i\ A)} \\
                          & & \qquad \to (B \in (A \to \sV_k)) \to (B_\varepsilon \in ((a \in A) \to \Upred_i\ (B\ a)))\\
                          & & \qquad \to \Upred_i\ {((a \in A) \to B\ a)}\\
                     & \sep & \tm{\codepisu}{(A \in \ssProp)} \\
                          & & \qquad \to (B \in (A \to \sV_i)) \to (B_\varepsilon \in ((a \in A) \to \Upred_i\ (B\ a)))\\
                          & & \qquad \to \Upred_i\ {((a \in A) \to B\ a)}\\
                     & \sep & \tm{\codesigma}{\{ j, k \in \metanat\ |\ \mathrm{max}(j, k) \le i\} \to (A \in \sV_j) \to (A_\varepsilon \in \Upred_i\ A)} \\
                          & & \qquad \to (B \in (A \to \sV_k)) \to (B_\varepsilon \in ((a \in A) \to \Upred_i\ (B\ a)))\\
                          & & \qquad \to \Upred_i\ {((a \in A) \times B\ a)}\\
                     & \sep & \tm{\codebox}{(A \in \ssProp) \to \Upred_i\ A} \\
                     & \sep & \tm{\codequo}{\{ j \in \metanat\ |\ j < i\} \to (A \in \sV_j) \to (A_\varepsilon \in \Upred_i\ A)} \\
                          & & \qquad \to \{ R \in A \to A \to \Two \ |\ R \text{ is an equivalence relation}\}\\
                          & & \qquad \to \Upred_i\ {(A/R)}\\
                     & \sep & \tm{\codeid}{\{ j \in \metanat\ |\ j < i\} \to (A \in \sV_j) \to (A_\varepsilon \in \Upred_i\ A)} \\
                          & & \qquad \to (x \in A) \to (y \in A)\\
                          & & \qquad \to \Upred_i\ \{ x \in \{ * \}\ |\ \sEq{t}{u} \}\\\
                     & \sep & \tm{\codeU}{\Fun{\{ j \in \metanat\ |\ j < i\}}{\Upred_i\ \sU_j}} \\
                     & \sep & \tm{\codesProp}{\Upred_i\ \ssProp} \\
  \end{array} &&
\end{flalign*}

\begin{flalign*}
  \hspace{5pt}\sU_i \quad := \quad (X \in \sV_i)\times(\Upred_i\ X) &&
\end{flalign*}
%
\begin{flalign*}
  &\hspace{5pt}\el \quad : \quad \sU_i \to \sV_i&\\
  &\hspace{5pt}\el\ (X\ ;\ X_\varepsilon)\ :=\ X&
\end{flalign*}
\end{small}
  \caption{The universe of codes, defined with set-theoretic inductive types}
  \label{fig:model}
\end{figure}

\subsection{Interpreting the Syntax of \SetoidCC}

Now that we know how to deal with the universes, it only
remains to spell out the interpretation of the full syntax of \SetoidCC.
%
In the standard fashion~\sidecite{hofmann95}, we define interpretation functions that send
\begin{itemize}
  \item a context \( \Gamma \) to a set \( \mctx{\Gamma} \), and
  \item a pair of a term \( t \) and a context \( \Gamma \) to a set \( \mty{t} \) indexed over \( \mctx{\Gamma} \).
\end{itemize}
Since these functions are defined on raw syntax without any guarantee of
well-typedness, we cannot expect every term to have a sensible interpretation
so we need to define them as partial functions. We will be able to prove
that all well-typed terms admit an interpretation \textit{a posteriori} by
induction on the derivations.

As usual, contexts are interpreted as telescopes:
\( \mctx{\emptyctx} = \{ * \} \) and
\( \mctx{\extctx{\Gamma}{A}} = (\rho : \mctx{\Gamma})\times (\mty{A}\ \rho) \)
when \( \mty{A} \) is defined.
%
Given \( \rho \in \mctx{\Gamma} \) and a variable \( x \) that appears in
\( \Gamma \), we write \( \rho(x) \) for the corresponding projection.

The interpretation of the terms is defined in \cref{fig:interpretation}. 
\begin{itemize}
\item In the proof-relevant fragment, we interpret types as elements of
  our decorated hierarchy \( \sU_1, \sU_2 ... \) and terms as sets.
  The intention is that if \( t \) is an inhabitant of
  the proof relevant term \( A \) in context \( \Gamma \), then its interpretation 
  \( \mty{t}\ \rho \) should be an element of \( \el\ (\mty{A}\ \rho) \) for all
  \( \rho \in \mctx{\Gamma} \).
\item In order to validate proposition extensionality, proof-irrelevant 
  propositions are directly interpreted as \emph{truth values}, or
  in other words, subsets of the singleton set.
  Computationally irrelevant proofs such as \( \metaop{refl} \) of 
  \( \metaop{\Box{-}elim} \) are all interpreted interpreted as \( \rho \mapsto * \),
  which guarantees that the corresponding proposition is true for all
  \( \rho \in \mctx{\Gamma} \).
  % 
  We can interpret cast as the identity, since the two types are interpreted
  as the same set, and \( \emptyrec{A}{t} \) is not even interpreted since it 
  can only be formed in inconsistent contexts, which are empty in the model.
\end{itemize}

In order to prove the soundness of our interpretation, we need to extend it to weakenings
and substitutions between contexts.
%
Assume \( \Gamma \) and \( \Delta \) are a syntactic contexts, and \( A \) and \( t \)
are syntactic terms.
%
In case \( \mctx{\Gamma, \tm{x}{A}, \Delta} \) and \( \mctx{\Gamma, \Delta} \) are well-defined,
let \( \pi_A \) be the projection:
{\small
\[
  \begin{split}
  \pi_A : \mctx{\Gamma, \tm{x}{A}, \Delta} & \to \mctx{\Gamma, \Delta} \\
  (\vec{x_\Gamma}, x_A, \vec{x_\Delta}) & \mapsto (\vec{x_\Gamma}, \vec{x_\Delta}).
  \end{split}
\]
}
In case \( \mctx{\Gamma, \subst{\Delta}{t}} \) and \( \mctx{\Gamma, \tm{x}{A}, \Delta} \) are
well-defined, we define the function \( \sigma_t \) by:
{\small
\[
  \begin{split}
    \sigma_t : \mctx{\Gamma, \subst{\Delta}{t}} & \to \mctx{\Gamma, \tm{x}{A}, \Delta} \\
    (\vec{x_\Gamma}, \vec{x_\Delta}) & \mapsto (\vec{x_\Gamma}, \mty{t}\ \vec{x_\Gamma}, \vec{x_\Delta}).
  \end{split}
\]
}
%
\begin{lemma}[Weakening]\label{lem:weakening}
  \( \pi_A \) is the semantic counterpart to the weakening of \( A \): for all terms \( u \),
  when both sides are well defined, we have:
  {\small
\[
    \mty[{\Gamma, \tm{x}{A}, \Delta}]{u} = \mty[{\Gamma, \Delta}]{u} \circ \pi_A
  \]}
\end{lemma}
%
\begin{lemma}[Substitution]\label{lem:substitution}\ \( \sigma_t \) is the semantic counterpart to the substitution by \( t \):
  for all terms \( u \), when both sides are well defined, we have:
  {\small
\[
    \mty[{\Gamma, \subst{\Delta}{t}}]{\subst{u}{t}} = \mty[{\Gamma, \tm{x}{A}, \Delta}]{u} \circ \sigma_t
  \]}
\end{lemma}

\begin{theorem}[Soundness of the Standard Model]
  \
  \begin{enumerate}
    \item If\, \( \wfctx{\Gamma} \) then \( \mctx{\Gamma} \) is defined.
    \item If\, \( \tytm{\Gamma}{A}{\sProp} \) then \( \mty{A}\ \rho \) is a subset of \( \{ * \} \) for all \( \rho \in \mctx{\Gamma} \).
    \item If\, \( \tytm{\Gamma}{A}{\Type_i} \) then \( \mty{A}\ \rho \) is in \( \sU_i \) for all \( \rho \in \mctx{\Gamma} \).
    \item If\, \( \tytmannotated{\Gamma}{t}{A}{\sProp} \) then \( \mty{A}\ \rho \) is equal to \( \{ * \} \) for all \( \rho \in \mctx{\Gamma} \).
    \item If\, \( \tytmannotated{\Gamma}{t}{A}{\Type_i} \) then \( \mty{t}\ \rho \) is in \( \el\ (\mty{A}\ \rho) \) for all \( \rho \in \mctx{\Gamma} \).
    \item If\, \( \eqtmannotated{\Gamma}{t}{u}{A}{\Univ} \) then \( \mty{t} = \mty{u} \).
  \end{enumerate}
\end{theorem}
\begin{proof}
  By induction on the typing derivations, using \cref{lem:weakening,lem:substitution}.
\end{proof}


\begin{figure*}
  \begin{small}
\[
\begin{array}{rcl}
  \mty{x}\ \rho & := & \rho(x) \\
  \mty{\Type_i}\ \rho & := & \langle \sU_i\ ;\ \codeU\ i \rangle \\
  \mty{\sProp}\ \rho & := & \langle \ssProp\ ;\ \codesProp \rangle\\
  \\
  \mty{\Depfunannotated[y]{F}{G}{}{\Type_j}{\Type_k}}\ \rho & := & \big\langle (x \in\el\ \mty{F}\ \rho)\to (\el\ \mty[{\extctx[x]{\Gamma}{F}}]{G}\ \langle \rho\ ;\ x\rangle)\\
& & ;\ \codepiuu\ j\ k\ (\mty{F}\ \rho)\ (x \mapsto \mty[{\extctx[x]{\Gamma}{F}}]{G}\ \langle \rho\ ;\ x\rangle) \big\rangle\\
  \mty{\Depfunannotated[y]{F}{G}{}{\sProp}{\Type_k}}\ \rho & := & \big\langle (x \in \mty{F}\ \rho)\to (\el\ \mty[{\extctx[x]{\Gamma}{F}}]{G}\ \langle \rho\ ;\ x\rangle)\\
& & ;\ \codepisu\ (\mty{F}\ \rho)\ (x \mapsto \mty[{\extctx[x]{\Gamma}{F}}]{G}\ \langle \rho\ ;\ x\rangle) \big\rangle\\
  \mty{\Depfunannotated[y]{F}{G}{}{\Type_j}{\sProp}}\ \rho & := & \forall x \in (\el\ \mty{F}\ \rho),\ \mty[{\extctx[x]{\Gamma}{F}}]{G}\ \langle \rho\ ;\ x\rangle\\
  \mty{\Depfunannotated[y]{F}{G}{}{\sProp}{\sProp}}\ \rho & := & (\mty{F}\ \rho) \Rightarrow (\mty[{\extctx[x]{\Gamma}{F}}]{G}\ \langle \rho\ ;\ *\rangle)\\
  \mty{\lam[x]{F}{t}}\ \rho & := & x \mapsto (\mty[{\extctx[x]{\Gamma}{F}}]{t}\ \langle \rho\ ;\ x\rangle)\\
  \mty{t\ u}\ \rho & := & (\mty{t}\ \rho)\ (\mty{u}\ \rho)\\
  \\
  \mty{\Depsumannotated[y]{F}{G}{}{\Type_j}{\Type_k}}\ \rho & := & \big\langle (x \in\el\ \mty{F}\ \rho)\times (\el\ \mty[{\extctx[x]{\Gamma}{F}}]{G}\ \langle \rho\ ;\ x\rangle)\\
& & ;\ \codesigma\ j\ k\ (\mty{F}\ \rho)\ (x \mapsto \mty[{\extctx[x]{\Gamma}{F}}]{G}\ \langle \rho\ ;\ x\rangle) \big\rangle\\
  \mty{\relpair{t}{u}}\ \rho & := & \langle \mty{t}\ \rho\ ;\ \mty{u}\ \rho \rangle \\
  \mty{\relfst{t}}\ \rho & := & \pi_1 (\mty{t}\ \rho) \\
  \mty{\relsnd{t}}\ \rho & := & \pi_2 (\mty{t}\ \rho) \\
  \\
  \mty{\Nat}\ \rho & := & \langle \metanat\ ;\ \codeemb\ \metanat \rangle \\
  \mty{\zero}\ \rho & := & \metazero \\
  \mty{\suc{t}}\ \rho & := & \metasuc{(\mty{t}\ \rho)} \\
  \mty{\natrec{P}{t_0}{t_S}{n}}\ \rho & := & \metanat\mathrm{-elim}(\el \circ (\mty{P}\ \rho), \mty{t_0}\ \rho, \mty{t_S}\ \rho, \mty{n}\ \rho)\\
  \\
  \mty{\Boxt{A}}\ \rho & := & \langle \mty{A}\ \rho\ ;\ \codebox\ (\mty{A}\ \rho) \rangle \\
  \mty{\boxt{t}}\ \rho & := & * \\
  \mty{\unboxt{t}}\ \rho & := & * \\
  \\
  \mty{\Quo{A}{R}}\ \rho & := & \langle (\mty{A}\ \rho)/(\mty{R}\ \rho)\ ;\ \codequo\ (\mty{A}\ \rho)\ (\mty{R}\ \rho) \rangle \\
  \mty{\quo{t}}\ \rho & := & \text{the equivalence class of } \mty{t}\ \rho \text{ in the quotient} \\
  \mty{\quorec{A}{t}{u}{v}}\ \rho & := & (\mty{t}\ \rho)\ x \qquad \text{for any } x \in (\mty{v}\ \rho)\\  
  \\
  \mty{\Id{A}{t}{u}}\ \rho & := & \langle \{ x \in \{ * \}\ |\ \sEq{\mty{t}\ \rho}{\mty{u}\ \rho} \} \\
& & ;\ \codeid\ (\mty{A}\ \rho)\ (\mty{t}\ \rho)\ (\mty{u}\ \rho) \rangle \\
  \mty{\id{t}}\ \rho & := & * \\
  \mty{\idpath{t}}\ \rho & := & * \\
  \mty{\J{A}{t}{B}{u}{t'}{e}}\ \rho & := & \mty{u}\ \rho \\
  \\
  \mty{\Empty}\ \rho & := & \emptyset \\
  \mty{\emptyrec{A}{t}}\ \rho & := & \text{undefined} \\
  \\
  \mty{\Obseq[A]{t}{u}}\ \rho & := & \{ x \in \{ * \}\ |\ \sEq{\mty{t}\ \rho}{\mty{u}\ \rho} \}\\
  \mty{\refl{t}{A}}\ \rho & := & * \\
  \mty{\transport{F}{t}{G}{u}{t'}{e}}\ \rho & := & * \\
  \mty{\cast{A}{B}{e}{t}}\ \rho & := & \mty{t}\ \rho\\
  \mty{\castrefl{A}{t}}\ \rho & := & *
\end{array}
\]
\end{small}
  \caption{Interpretation of \SetoidCC in the Standard Model}
  \label{fig:interpretation}
\end{figure*}

\subsection{Consequences of the Model}

From the soundness theorem and the interpretation of \( \bot \) being empty,
the consistency of \SetoidCC is immediate:

\begin{theorem}[Consistency]
  There are no proofs of \( \bot \) in the empty context.
\end{theorem}

Furthermore, by inspecting the normal forms provided by the normalization
theorem, we realize that \( \castName \) is the only way to build a neutral
term in the absence of variables. But having a stuck \( \castName \) requires
having an equality proof between two incompatible types, which contradicts
consistency.

\begin{theorem}
  There are no neutral terms in the empty context.
\end{theorem}

From there, we deduce the canonicity theorem: all integers reduce to
standard integers in the empty context. Thus, our modified model still allows
us to establish all of the important meta-theoretical properties.

On the other hand, it seems difficult to measure to what extent our
set-theoretic model presents
\SetoidCC as a good internal language for sets. Compared to the universe
construction of \sidecitet{pujet:hal-03367052}, we gain the property that every set belongs
to a universe---meaning that theorems which quantify over \( \Type_i \)
will apply to all sufficiently small sets.
%
Of course, this does not prevent us from proving some theorems that are
obviously false in classical mathematics, such as the
injectivity of type formers. But we would argue that all such results
are artifacts of the choice of encodings, and not meaningful
mathematical statements.

